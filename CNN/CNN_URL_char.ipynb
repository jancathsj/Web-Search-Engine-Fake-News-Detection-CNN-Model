{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b88e8e-e454-49d2-ad8e-8e63defc99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%%script C:\\Users\\Jan Catherine\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6882c84-4ec7-4025-862c-e30f906994de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57500b2d-3257-4427-9f33-9d055fc284e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../Data_Collection_02/02_Preprocessing/05_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8863d932-63b8-4c2b-a9bf-cc584f2b6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5f248c-54b6-4365-af00-0637fb458e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Activation, Flatten\\nfrom keras.layers import Convolution2D, MaxPooling2D\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd\\nimport numpy as np\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61db8ea8-a355-4d58-b625-4013889267b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31ffad0-8c40-4997-91a8-c775cb33d04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "-------Train data--------\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "11520\n",
      "-------------------------\n",
      "-------Test data--------\n",
      "0    1429\n",
      "1     184\n",
      "Name: Fake, dtype: int64\n",
      "1613\n",
      "-------------------------\n",
      "Train Max Length :255\n",
      "Test Max Sentence Length :250\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('01_URL_Train.csv', encoding='latin-1')\n",
    "testdata = pd.read_csv('01_URL_Test.csv', encoding='latin-1')\n",
    "\n",
    "train_data = dataset\n",
    "test_data = testdata\n",
    "\n",
    "#Oversampling\n",
    "count_class_0, count_class_1 = train_data.Fake.value_counts()\n",
    "\n",
    "df_class_0 = train_data[train_data['Fake'] == 0]\n",
    "df_class_1 = train_data[train_data['Fake'] == 1]\n",
    "\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "df_test_over = df_test_over.reset_index(drop=True)\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Fake.value_counts())\n",
    "\n",
    "train_data = df_test_over\n",
    "\n",
    "print(train_data.Fake.value_counts())\n",
    "\n",
    "train_data.dropna(axis=0, how ='any', inplace=True)\n",
    "train_data['Num_words_url'] = train_data['URL'].apply(lambda x:len(str(x)))\n",
    "\n",
    "print('-------Train data--------')\n",
    "print(train_data['Fake'].value_counts())\n",
    "print(len(train_data))\n",
    "print('-------------------------')\n",
    "\n",
    "max_train_url_length  = train_data['Num_words_url'].max()\n",
    "\n",
    "\n",
    "\n",
    "test_data.dropna(axis = 0, how ='any',inplace=True) \n",
    "test_data['Num_words_url'] = test_data['URL'].apply(lambda x:len(str(x))) \n",
    "\n",
    "max_test_url_length  = test_data['Num_words_url'].max()\n",
    "\n",
    "print('-------Test data--------')\n",
    "print(test_data['Fake'].value_counts())\n",
    "print(len(test_data))\n",
    "print('-------------------------')\n",
    "\n",
    "print('Train Max Length :'+str(max_train_url_length))\n",
    "print('Test Max Sentence Length :'+str(max_test_url_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a2bbef-3563-46e8-a7b6-960806b53caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Num_words_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.thehindu.com/opinion/lead/a-key-ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mckinsey.com/industries/financial-...</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://coronadotimes.com/news/2020/06/14/nail...</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://aricjournal.biomedcentral.com/articles...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.idealista.com/en/news/property-for...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Fake  Num_words_url\n",
       "0  https://www.thehindu.com/opinion/lead/a-key-ar...     0            102\n",
       "1  https://www.mckinsey.com/industries/financial-...     0            150\n",
       "2  https://coronadotimes.com/news/2020/06/14/nail...     0            107\n",
       "3  https://aricjournal.biomedcentral.com/articles...     0             73\n",
       "4  https://www.idealista.com/en/news/property-for...     0            144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21264bed-6b54-438e-b82e-8fe0913d7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34, 24, 1, 24, 15, 6, 25, 8, 15, 1, 25, 9, 15, 15, 1, 8, 9, 11, 28, 8, 11, 3]]\n"
     ]
    }
   ],
   "source": [
    "num_words = 12000\n",
    "\n",
    "\n",
    "URLchar = Tokenizer(num_words=num_words, oov_token=\"unk\", char_level=True)\n",
    "URLchar.fit_on_texts(train_data['URL'].tolist())\n",
    "\n",
    "print(str(URLchar.texts_to_sequences(['5G Global bill airfare'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fbc624-d2a4-41b1-be0a-e7683b4d2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:9216\n",
      "Class distributionCounter({0: 4608, 1: 4608})\n",
      "Valid data len:2304\n",
      "Class distributionCounter({1: 1152, 0: 1152})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_11248\\1508549292.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array( URLchar.texts_to_sequences(X_train) )\n",
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_11248\\1508549292.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_valid = np.array( URLchar.texts_to_sequences(X_valid) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  4  4 16  5 27  7  7 13 13 13 17 10  3 13  5 26 35 17 12  6 19  7 10\n",
      "  3 13  5  7  9 10 20  9  8  7 10  3 13  5  2  6 28  2 12 14  9 10  3  5\n",
      "  3  2 15  8 25  2 12 11  3  8  4  9 10 24  2  8 10  4 14 11  8 39  2 15\n",
      "  9 30  3  2 16  8  4 14  6 24  3 10  5  2  9 10  2 16  8 30  9  5  4  8\n",
      " 10  2 28  8 30  3  2  5  8 29  5  2  9  4  5  2 28  6 11  3  9 24 10  2\n",
      "  6 28 28  9 12  3  2 23 37 32 36 26 23 31 17 14  4 19 15  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_11248\\1508549292.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test  = np.array( URLchar.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data['URL'].tolist(),\\\n",
    "                                                      train_data['Fake'].tolist(),\\\n",
    "                                                      test_size=0.2,\\\n",
    "                                                      stratify = train_data['Fake'].tolist(),\\\n",
    "                                                      random_state=0)\n",
    "\n",
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution'+str(Counter(y_train)))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution'+ str(Counter(y_valid)))\n",
    "\n",
    "x_train = np.array( URLchar.texts_to_sequences(X_train) )\n",
    "x_valid = np.array( URLchar.texts_to_sequences(X_valid) )\n",
    "x_test  = np.array( URLchar.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=260)\n",
    "x_valid = pad_sequences(x_valid, padding='post', maxlen=260)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=260)\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_labels = le.fit_transform(y_train)\n",
    "train_labels = np.asarray( tf.keras.utils.to_categorical(train_labels, 2))\n",
    "#print(train_labels)\n",
    "valid_labels = le.transform(y_valid)\n",
    "valid_labels = np.asarray( tf.keras.utils.to_categorical(valid_labels, 2))\n",
    "\n",
    "\n",
    "test_labels = le.transform(test_data['Fake'].tolist())\n",
    "test_labels = np.asarray(tf.keras.utils.to_categorical(test_labels, 2))\n",
    "list(le.classes_)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,train_labels))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0143d15f-85f2-4690-8a64-e438f3f4656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Num_words_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://bhekisisa.org/article/2020-06-03-coron...</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.express.co.uk/travel/articles/1246...</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.thesun.co.uk/tvandshowbiz/11851914...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.inquirer.com/opinion/china-reparat...</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://scdhec.gov/covid19/covid-19-testing-lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Fake  Num_words_url\n",
       "0  https://bhekisisa.org/article/2020-06-03-coron...     0            139\n",
       "1  https://www.express.co.uk/travel/articles/1246...     0            132\n",
       "2  https://www.thesun.co.uk/tvandshowbiz/11851914...     0             87\n",
       "3  https://www.inquirer.com/opinion/china-reparat...     0             98\n",
       "4  https://scdhec.gov/covid19/covid-19-testing-lo...     0             53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bf38b8-3b43-49a7-a1b8-90da4888318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Train dataset ====\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17 10  3 13  5 26 35 17 12  6 19  7 10\n",
      "  3 13  5  7  9 10 20  9  8  7 10  3 13  5  2  6 28  2 12 14  9 10  3  5\n",
      "  3  2 15  8 25  2 12 11  3  8  4  9 10 24  2  8 10  4 14 11  8 39  2 15\n",
      "  9 30  3  2 16  8  4 14  6 24  3 10  5  2  9 10  2 16  8 30  9  5  4  8\n",
      " 10  2 28  8 30  3  2  5  8 29  5  2  9  4  5  2 28  6 11  3  9 24 10  2\n",
      "  6 28 28  9 12  3  2 23 37 32 36 26 23 31 17 14  4 19 15  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 24  9 40 19  6 20  6 17 12  6 19 17  8 18  7 23\n",
      " 21 23 21  7 21 32  7 24  6 22  3 11 10 19  3 10  4  2  4 11  8 12 30  9\n",
      " 10 24  2  6 28  2 19  6 25  9 15  3  2 16 14  6 10  3  5  2 12  6 18 15\n",
      " 20  2 25  3  2  8  2 16  6  4  3 10  4  2 13  3  8 16  6 10  2  8 24  8\n",
      "  9 10  5  4  2 12  6 22  9 20  2 26 31  7  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17 13 18 10 12 17  6 11 24  7 19  9 15\n",
      "  9  4  8 11 29  7 23 21 23 21  2 21 33  2 21 36  7 12  6 11  6 10  8 22\n",
      "  9 11 18  5  2 18 16  3 10 20  5  2 19  9 15  9  4  8 11 29  2 28 18 10\n",
      "  3 11  8 15  5  2 11  9  4 18  8 15  5  2 28  6 11  2 28  8 19  9 15  9\n",
      "  3  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "======Validation dataset ====\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17 20  8 15 15  8  5 10  3 13  5 17 12\n",
      "  6 19  7 10  3 13  5  7 16 18 25 15  9 12  2 14  3  8 15  4 14  7 23 21\n",
      " 23 21  7 21 32  7 26 35  7 20  8 15 15  8  5  2 28  3 20  3 11  8 15  2\n",
      " 15  8 13  5 18  9  4  2  8 12 12 18  5  3  5  2 12 14  9 10  3  5  3  2\n",
      " 24  6 22  3 11 10 19  3 10  4  2  6 28  2 12 11  3  8  4  9 10 24  2 12\n",
      "  6 11  6 10  8 22  9 11 18  5  2  8  5  2 25  9  6 15  6 24  9 12  8 15\n",
      "  2 13  3  8 16  6 10  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17 20  8  9 15 29  5  4  8 11 17 12  6\n",
      " 17 18 30  7 10  3 13  5  7 13  6 11 15 20  2 10  3 13  5  7  9 10 28  3\n",
      " 12  4  3 20  2 16  3  6 16 15  3  2  5  3  3 10  2 20  3  8 20  2  5  4\n",
      " 11  3  3  4  5  2 23 26 32 33 34 34 35 34  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17 10 29  4  9 19  3  5 17 12  6 19  7\n",
      " 23 21 23 21  7 21 33  7 26 31  7 13  6 11 15 20  7  8  5  9  8  7  4  6\n",
      " 30 29  6  2 38  8 16  8 10  2 12  6 11  6 10  8 22  9 11 18  5 17 14  4\n",
      " 19 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "======Test dataset ====\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 25 14  3 30  9  5  9  5  8 17  6 11 24  7  8 11\n",
      "  4  9 12 15  3  7 23 21 23 21  2 21 36  2 21 32  2 12  6 11  6 10  8 22\n",
      "  9 11 18  5  2 28  8 12  4  2 12 14  3 12 30  2 20  6  3  5  2  4 14  3\n",
      "  2 11  3 12 29 12 15  3 20  2  8  9 11  2  6 10  2 16 15  8 10  3  5  2\n",
      " 11  3  8 15 15 29  2 16 18  4  2 29  6 18  2  8  4  2  8  2 14  9 24 14\n",
      "  2 11  9  5 30  2  6 28  2  9 10 28  3 12  4  9  6 10  7  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17  3 39 16 11  3  5  5 17 12  6 17 18\n",
      " 30  7  4 11  8 22  3 15  7  8 11  4  9 12 15  3  5  7 26 23 33 36 36 37\n",
      " 21  7 12  6 11  6 10  8 22  9 11 18  5  2  9  4  8 15 29  2  4 11  8 22\n",
      "  3 15  2  8 20 22  9 12  3  2  9  5  2  9  4  2  5  8 28  3  2  4  6  2\n",
      "  4 11  8 22  3 15  2  4  6  2  9  4  8 15 29  2 28 12  6  2 13  8 11 10\n",
      "  9 10 24  2 12  6 22  9 20  2 26 31  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[14  4  4 16  5 27  7  7 13 13 13 17  4 14  3  5 18 10 17 12  6 17 18 30\n",
      "  7  4 22  8 10 20  5 14  6 13 25  9 40  7 26 26 35 34 26 31 26 33  7 13\n",
      "  8 29 10  3  2 11  6  6 10  3 29  2  4 11  9 25 18  4  3  2 12  6 15  3\n",
      "  3 10  2  8 10 10  9 22  3 11  5  8 11 29  7  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(260,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "print('======Train dataset ====')\n",
    "for value,label in train_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break\n",
    "count =0\n",
    "print('======Validation dataset ====')\n",
    "for value,label in valid_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break\n",
    "count = 0\n",
    "print('======Test dataset ====')\n",
    "for value,label in test_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dc6838-cfe5-4647-8591-125720406e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 38ms/step - loss: 0.7033 - categorical_accuracy: 0.6314\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.6006 - categorical_accuracy: 0.7114\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.5538 - categorical_accuracy: 0.7567\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.5192 - categorical_accuracy: 0.7959\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.4996 - categorical_accuracy: 0.8094\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.4743 - categorical_accuracy: 0.8301\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.4639 - categorical_accuracy: 0.8401\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.4530 - categorical_accuracy: 0.8478\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.4411 - categorical_accuracy: 0.8555\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.4324 - categorical_accuracy: 0.8657\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.4259 - categorical_accuracy: 0.8745\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.4184 - categorical_accuracy: 0.8761\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.4121 - categorical_accuracy: 0.8834\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.4098 - categorical_accuracy: 0.8863\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.4008 - categorical_accuracy: 0.8920\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.4006 - categorical_accuracy: 0.8936\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.4013 - categorical_accuracy: 0.8965\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3971 - categorical_accuracy: 0.8992\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3946 - categorical_accuracy: 0.8976\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3883 - categorical_accuracy: 0.9076\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3958 - categorical_accuracy: 0.8993\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 18s 63ms/step - loss: 0.3854 - categorical_accuracy: 0.9081\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 20s 68ms/step - loss: 0.3796 - categorical_accuracy: 0.9116\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3836 - categorical_accuracy: 0.9102\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3836 - categorical_accuracy: 0.9086\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3809 - categorical_accuracy: 0.9128\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3774 - categorical_accuracy: 0.9157\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3801 - categorical_accuracy: 0.9142\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3785 - categorical_accuracy: 0.9174\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.3731 - categorical_accuracy: 0.9214\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 17s 60ms/step - loss: 0.3744 - categorical_accuracy: 0.9175\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3740 - categorical_accuracy: 0.9178\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.3723 - categorical_accuracy: 0.9188\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3743 - categorical_accuracy: 0.9187\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3748 - categorical_accuracy: 0.9201\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3688 - categorical_accuracy: 0.9234\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3706 - categorical_accuracy: 0.9252\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.3697 - categorical_accuracy: 0.9240\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3738 - categorical_accuracy: 0.9233\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3679 - categorical_accuracy: 0.9264\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3723 - categorical_accuracy: 0.9234\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3715 - categorical_accuracy: 0.9260\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.3642 - categorical_accuracy: 0.9301\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.3665 - categorical_accuracy: 0.9270\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3701 - categorical_accuracy: 0.9260\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 18s 61ms/step - loss: 0.3708 - categorical_accuracy: 0.9263\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3679 - categorical_accuracy: 0.9274\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3709 - categorical_accuracy: 0.9278\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3650 - categorical_accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3606 - categorical_accuracy: 0.9293\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.3567 - categorical_accuracy: 0.9350\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3627 - categorical_accuracy: 0.9289\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3652 - categorical_accuracy: 0.9280\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 19s 66ms/step - loss: 0.3620 - categorical_accuracy: 0.9306\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.3631 - categorical_accuracy: 0.9300\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3619 - categorical_accuracy: 0.9311\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3617 - categorical_accuracy: 0.9302\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3635 - categorical_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3572 - categorical_accuracy: 0.9366\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.3617 - categorical_accuracy: 0.9304\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3578 - categorical_accuracy: 0.9348\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3655 - categorical_accuracy: 0.9277\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3645 - categorical_accuracy: 0.9283\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 18s 62ms/step - loss: 0.3591 - categorical_accuracy: 0.9344\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3593 - categorical_accuracy: 0.9353\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3593 - categorical_accuracy: 0.9350\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3613 - categorical_accuracy: 0.9334\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.3573 - categorical_accuracy: 0.9347\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3598 - categorical_accuracy: 0.9336\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3565 - categorical_accuracy: 0.9371\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.3557 - categorical_accuracy: 0.9373\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3536 - categorical_accuracy: 0.9372\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3530 - categorical_accuracy: 0.9366\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3587 - categorical_accuracy: 0.9334\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3563 - categorical_accuracy: 0.9377\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3538 - categorical_accuracy: 0.9364\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3558 - categorical_accuracy: 0.9357\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3585 - categorical_accuracy: 0.9358\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3515 - categorical_accuracy: 0.9402\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3563 - categorical_accuracy: 0.9340\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3468 - categorical_accuracy: 0.9418\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3520 - categorical_accuracy: 0.9406\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3588 - categorical_accuracy: 0.9363\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3553 - categorical_accuracy: 0.9391\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 19s 65ms/step - loss: 0.3482 - categorical_accuracy: 0.9403\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3535 - categorical_accuracy: 0.9389\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3555 - categorical_accuracy: 0.9401\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.3556 - categorical_accuracy: 0.9396\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 18s 61ms/step - loss: 0.3500 - categorical_accuracy: 0.9410\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 19s 65ms/step - loss: 0.3513 - categorical_accuracy: 0.9377\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3531 - categorical_accuracy: 0.9374\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3508 - categorical_accuracy: 0.9405\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3561 - categorical_accuracy: 0.9364\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.3537 - categorical_accuracy: 0.9370\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3543 - categorical_accuracy: 0.9398\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3555 - categorical_accuracy: 0.9397\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 17s 57ms/step - loss: 0.3507 - categorical_accuracy: 0.9422\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3525 - categorical_accuracy: 0.9377\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3529 - categorical_accuracy: 0.9401\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3485 - categorical_accuracy: 0.9441\n",
      "Score for fold 1: loss of 0.3239861726760864; categorical_accuracy of 95.87673544883728%\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 39ms/step - loss: 0.7012 - categorical_accuracy: 0.6224\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.5971 - categorical_accuracy: 0.7121\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.5497 - categorical_accuracy: 0.7568\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.5209 - categorical_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.4975 - categorical_accuracy: 0.8102\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.4796 - categorical_accuracy: 0.8273\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.4687 - categorical_accuracy: 0.8358\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.4568 - categorical_accuracy: 0.8462\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.4511 - categorical_accuracy: 0.8520\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.4372 - categorical_accuracy: 0.8632\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.4280 - categorical_accuracy: 0.8715\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.4283 - categorical_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.4222 - categorical_accuracy: 0.8747\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.4212 - categorical_accuracy: 0.8785\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.4152 - categorical_accuracy: 0.8862\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.4149 - categorical_accuracy: 0.8843\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.4061 - categorical_accuracy: 0.8916\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3985 - categorical_accuracy: 0.8912\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.4001 - categorical_accuracy: 0.8983\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3995 - categorical_accuracy: 0.8938\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3937 - categorical_accuracy: 0.8987\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3921 - categorical_accuracy: 0.9028\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3873 - categorical_accuracy: 0.9042\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3949 - categorical_accuracy: 0.8998\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3893 - categorical_accuracy: 0.9051\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3871 - categorical_accuracy: 0.9066\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.3883 - categorical_accuracy: 0.9079\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 17s 60ms/step - loss: 0.3880 - categorical_accuracy: 0.9078\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3843 - categorical_accuracy: 0.9113\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3822 - categorical_accuracy: 0.9110\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3793 - categorical_accuracy: 0.9173\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 18s 62ms/step - loss: 0.3821 - categorical_accuracy: 0.9130\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3815 - categorical_accuracy: 0.9133\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3752 - categorical_accuracy: 0.9182\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3837 - categorical_accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3778 - categorical_accuracy: 0.9182\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3780 - categorical_accuracy: 0.9164\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 17s 60ms/step - loss: 0.3751 - categorical_accuracy: 0.9181\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 18s 63ms/step - loss: 0.3734 - categorical_accuracy: 0.9202\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3709 - categorical_accuracy: 0.9217\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3754 - categorical_accuracy: 0.9186\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3698 - categorical_accuracy: 0.9221\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3688 - categorical_accuracy: 0.9240\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3718 - categorical_accuracy: 0.9215\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3694 - categorical_accuracy: 0.9252\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3693 - categorical_accuracy: 0.9234\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3713 - categorical_accuracy: 0.9226\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3758 - categorical_accuracy: 0.9209\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3667 - categorical_accuracy: 0.9249\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3644 - categorical_accuracy: 0.9256\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3699 - categorical_accuracy: 0.9238\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3656 - categorical_accuracy: 0.9249\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3675 - categorical_accuracy: 0.9246\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3675 - categorical_accuracy: 0.9265\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3670 - categorical_accuracy: 0.9271\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3656 - categorical_accuracy: 0.9284\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.3658 - categorical_accuracy: 0.9285\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3644 - categorical_accuracy: 0.9315\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3627 - categorical_accuracy: 0.9307\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3640 - categorical_accuracy: 0.9286\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3577 - categorical_accuracy: 0.9317\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3630 - categorical_accuracy: 0.9306\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3599 - categorical_accuracy: 0.9321\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3575 - categorical_accuracy: 0.9336\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3650 - categorical_accuracy: 0.9288\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3634 - categorical_accuracy: 0.9282\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3623 - categorical_accuracy: 0.9293\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3615 - categorical_accuracy: 0.9307\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3568 - categorical_accuracy: 0.9316\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3583 - categorical_accuracy: 0.9351\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3597 - categorical_accuracy: 0.9331\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3617 - categorical_accuracy: 0.9322\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3612 - categorical_accuracy: 0.9320\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3571 - categorical_accuracy: 0.9353\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3574 - categorical_accuracy: 0.9346\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3578 - categorical_accuracy: 0.9317\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3591 - categorical_accuracy: 0.9344\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.3582 - categorical_accuracy: 0.9335\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3603 - categorical_accuracy: 0.9344\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3579 - categorical_accuracy: 0.9341\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3596 - categorical_accuracy: 0.9346\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.3514 - categorical_accuracy: 0.9382\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3539 - categorical_accuracy: 0.9387\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3566 - categorical_accuracy: 0.9345\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3558 - categorical_accuracy: 0.9329\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3531 - categorical_accuracy: 0.9375\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3572 - categorical_accuracy: 0.9366\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3514 - categorical_accuracy: 0.9402\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3568 - categorical_accuracy: 0.9355\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3571 - categorical_accuracy: 0.9368\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3521 - categorical_accuracy: 0.9363\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3562 - categorical_accuracy: 0.9347\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3561 - categorical_accuracy: 0.9346\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3553 - categorical_accuracy: 0.9349\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3503 - categorical_accuracy: 0.9397\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3528 - categorical_accuracy: 0.9393\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3555 - categorical_accuracy: 0.9378\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3538 - categorical_accuracy: 0.9371\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 15s 50ms/step - loss: 0.3542 - categorical_accuracy: 0.9352\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3553 - categorical_accuracy: 0.9393\n",
      "Score for fold 2: loss of 0.32738861441612244; categorical_accuracy of 96.26736044883728%\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 20s 64ms/step - loss: 0.7002 - categorical_accuracy: 0.6258\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.5994 - categorical_accuracy: 0.7135\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.5628 - categorical_accuracy: 0.7442\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.5335 - categorical_accuracy: 0.7780\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.5104 - categorical_accuracy: 0.8049\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.4938 - categorical_accuracy: 0.8153\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.4770 - categorical_accuracy: 0.8295\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.4643 - categorical_accuracy: 0.8391\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.4554 - categorical_accuracy: 0.8507\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.4440 - categorical_accuracy: 0.8570\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.4368 - categorical_accuracy: 0.8675\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.4345 - categorical_accuracy: 0.8695\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.4246 - categorical_accuracy: 0.8746\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.4257 - categorical_accuracy: 0.8778\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.4213 - categorical_accuracy: 0.8824\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.4172 - categorical_accuracy: 0.8849\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.4168 - categorical_accuracy: 0.8861\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.4080 - categorical_accuracy: 0.8937\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.4040 - categorical_accuracy: 0.8937\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.4015 - categorical_accuracy: 0.8991\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3998 - categorical_accuracy: 0.8964\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.4006 - categorical_accuracy: 0.8992\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3943 - categorical_accuracy: 0.9031\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3977 - categorical_accuracy: 0.9039\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3965 - categorical_accuracy: 0.9020\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.3952 - categorical_accuracy: 0.9046\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3883 - categorical_accuracy: 0.9109\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3912 - categorical_accuracy: 0.9090\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3872 - categorical_accuracy: 0.9090\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3834 - categorical_accuracy: 0.9130\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3837 - categorical_accuracy: 0.9110\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3895 - categorical_accuracy: 0.9094\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3843 - categorical_accuracy: 0.9123\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3814 - categorical_accuracy: 0.9157\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3809 - categorical_accuracy: 0.9135\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3809 - categorical_accuracy: 0.9173\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3748 - categorical_accuracy: 0.9220\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3771 - categorical_accuracy: 0.9186\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3835 - categorical_accuracy: 0.9175\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3780 - categorical_accuracy: 0.9179\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3766 - categorical_accuracy: 0.9191\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3719 - categorical_accuracy: 0.9239\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.3712 - categorical_accuracy: 0.9238\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3720 - categorical_accuracy: 0.9262\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3730 - categorical_accuracy: 0.9245\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3720 - categorical_accuracy: 0.9284\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3700 - categorical_accuracy: 0.9236\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.3678 - categorical_accuracy: 0.9266\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3714 - categorical_accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3681 - categorical_accuracy: 0.9290\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3694 - categorical_accuracy: 0.9278\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3699 - categorical_accuracy: 0.9266\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3702 - categorical_accuracy: 0.9245\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3687 - categorical_accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3615 - categorical_accuracy: 0.9312\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3685 - categorical_accuracy: 0.9308\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3682 - categorical_accuracy: 0.9261\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3677 - categorical_accuracy: 0.9308\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3630 - categorical_accuracy: 0.9321\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3718 - categorical_accuracy: 0.9297\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3625 - categorical_accuracy: 0.9339\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3605 - categorical_accuracy: 0.9316\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3597 - categorical_accuracy: 0.9339\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3612 - categorical_accuracy: 0.9353\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3630 - categorical_accuracy: 0.9319\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3630 - categorical_accuracy: 0.9321\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3582 - categorical_accuracy: 0.9338\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3617 - categorical_accuracy: 0.9304\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3560 - categorical_accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3526 - categorical_accuracy: 0.9360\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3577 - categorical_accuracy: 0.9368\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3627 - categorical_accuracy: 0.9344\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3643 - categorical_accuracy: 0.9327\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3576 - categorical_accuracy: 0.9359\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3600 - categorical_accuracy: 0.9374\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3597 - categorical_accuracy: 0.9352\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3593 - categorical_accuracy: 0.9342\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3599 - categorical_accuracy: 0.9353\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.3545 - categorical_accuracy: 0.9351\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3567 - categorical_accuracy: 0.9397\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3580 - categorical_accuracy: 0.9376\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3576 - categorical_accuracy: 0.9341\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3595 - categorical_accuracy: 0.9365\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3587 - categorical_accuracy: 0.9376\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3567 - categorical_accuracy: 0.9382\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 18s 62ms/step - loss: 0.3623 - categorical_accuracy: 0.9340\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3579 - categorical_accuracy: 0.9374\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3521 - categorical_accuracy: 0.9414\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3544 - categorical_accuracy: 0.9386\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3604 - categorical_accuracy: 0.9368\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3571 - categorical_accuracy: 0.9388\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3539 - categorical_accuracy: 0.9371\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3544 - categorical_accuracy: 0.9377\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3529 - categorical_accuracy: 0.9385\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3538 - categorical_accuracy: 0.9392\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.3540 - categorical_accuracy: 0.9386\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3549 - categorical_accuracy: 0.9399\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3514 - categorical_accuracy: 0.9408\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3475 - categorical_accuracy: 0.9431\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3560 - categorical_accuracy: 0.9406\n",
      "Score for fold 3: loss of 0.331327885389328; categorical_accuracy of 95.78993320465088%\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.6987 - categorical_accuracy: 0.6334\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 15s 50ms/step - loss: 0.5948 - categorical_accuracy: 0.7151\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.5510 - categorical_accuracy: 0.7611\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.5229 - categorical_accuracy: 0.7878\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.5051 - categorical_accuracy: 0.8010\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.4859 - categorical_accuracy: 0.8188\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.4721 - categorical_accuracy: 0.8338\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.4635 - categorical_accuracy: 0.8431\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.4511 - categorical_accuracy: 0.8460\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.4345 - categorical_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.4336 - categorical_accuracy: 0.8670\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.4369 - categorical_accuracy: 0.8622\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.4189 - categorical_accuracy: 0.8771\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.4187 - categorical_accuracy: 0.8783\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.4117 - categorical_accuracy: 0.8827\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.4092 - categorical_accuracy: 0.8869\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.4110 - categorical_accuracy: 0.8916\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.4050 - categorical_accuracy: 0.8913\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.4028 - categorical_accuracy: 0.8905\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3967 - categorical_accuracy: 0.8977\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.4023 - categorical_accuracy: 0.8940\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3943 - categorical_accuracy: 0.9010\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3888 - categorical_accuracy: 0.9073\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3930 - categorical_accuracy: 0.9039\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3882 - categorical_accuracy: 0.9081\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3892 - categorical_accuracy: 0.9051\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3898 - categorical_accuracy: 0.9069\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3840 - categorical_accuracy: 0.9130\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3792 - categorical_accuracy: 0.9146\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3903 - categorical_accuracy: 0.9091\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3802 - categorical_accuracy: 0.9176\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3775 - categorical_accuracy: 0.9140\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3789 - categorical_accuracy: 0.9187\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3753 - categorical_accuracy: 0.9171\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3756 - categorical_accuracy: 0.9197\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.3762 - categorical_accuracy: 0.9199\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3717 - categorical_accuracy: 0.9234\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3716 - categorical_accuracy: 0.9227\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3777 - categorical_accuracy: 0.9207\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3693 - categorical_accuracy: 0.9260\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3723 - categorical_accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3750 - categorical_accuracy: 0.9210\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3746 - categorical_accuracy: 0.9212\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3699 - categorical_accuracy: 0.9281\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.3751 - categorical_accuracy: 0.9212\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3708 - categorical_accuracy: 0.9220\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3744 - categorical_accuracy: 0.9226\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3665 - categorical_accuracy: 0.9280\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3690 - categorical_accuracy: 0.9253\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3639 - categorical_accuracy: 0.9313\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3616 - categorical_accuracy: 0.9308\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3701 - categorical_accuracy: 0.9233\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3680 - categorical_accuracy: 0.9259\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3621 - categorical_accuracy: 0.9319\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3637 - categorical_accuracy: 0.9313\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3625 - categorical_accuracy: 0.9312\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3702 - categorical_accuracy: 0.9263\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3696 - categorical_accuracy: 0.9293\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3629 - categorical_accuracy: 0.9294\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3623 - categorical_accuracy: 0.9335\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3600 - categorical_accuracy: 0.9309\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3702 - categorical_accuracy: 0.9281\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3652 - categorical_accuracy: 0.9320\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3628 - categorical_accuracy: 0.9283\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3566 - categorical_accuracy: 0.9379\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3618 - categorical_accuracy: 0.9324\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3566 - categorical_accuracy: 0.9347\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.3620 - categorical_accuracy: 0.9324\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3627 - categorical_accuracy: 0.9300\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3577 - categorical_accuracy: 0.9361\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3586 - categorical_accuracy: 0.9315\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3611 - categorical_accuracy: 0.9345\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3625 - categorical_accuracy: 0.9316\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3597 - categorical_accuracy: 0.9304\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3615 - categorical_accuracy: 0.9321\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3595 - categorical_accuracy: 0.9342\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3597 - categorical_accuracy: 0.9333\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3561 - categorical_accuracy: 0.9353\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3558 - categorical_accuracy: 0.9367\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3607 - categorical_accuracy: 0.9341\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3563 - categorical_accuracy: 0.9338\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3601 - categorical_accuracy: 0.9345\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3579 - categorical_accuracy: 0.9349\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3612 - categorical_accuracy: 0.9322\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 18s 63ms/step - loss: 0.3542 - categorical_accuracy: 0.9367\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3603 - categorical_accuracy: 0.9355\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3593 - categorical_accuracy: 0.9362\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3580 - categorical_accuracy: 0.9385\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3555 - categorical_accuracy: 0.9385\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3581 - categorical_accuracy: 0.9339\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3522 - categorical_accuracy: 0.9364\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3574 - categorical_accuracy: 0.9339\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3523 - categorical_accuracy: 0.9409\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3570 - categorical_accuracy: 0.9335\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3480 - categorical_accuracy: 0.9419\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 15s 54ms/step - loss: 0.3589 - categorical_accuracy: 0.9385\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.3542 - categorical_accuracy: 0.9366\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3535 - categorical_accuracy: 0.9391\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3531 - categorical_accuracy: 0.9378\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3566 - categorical_accuracy: 0.9379\n",
      "Score for fold 4: loss of 0.3255639970302582; categorical_accuracy of 95.61631679534912%\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 17s 53ms/step - loss: 0.7004 - categorical_accuracy: 0.6293\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.6004 - categorical_accuracy: 0.7104\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.5505 - categorical_accuracy: 0.7603\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.5198 - categorical_accuracy: 0.7910\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.4954 - categorical_accuracy: 0.8163\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.4708 - categorical_accuracy: 0.8317\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.4645 - categorical_accuracy: 0.8403\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.4491 - categorical_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.4356 - categorical_accuracy: 0.8645\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.4343 - categorical_accuracy: 0.8672\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.4209 - categorical_accuracy: 0.8738\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 18s 61ms/step - loss: 0.4178 - categorical_accuracy: 0.8827\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.4112 - categorical_accuracy: 0.8842\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.4112 - categorical_accuracy: 0.8855\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.4011 - categorical_accuracy: 0.8956\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3989 - categorical_accuracy: 0.8958\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3941 - categorical_accuracy: 0.8983\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.3851 - categorical_accuracy: 0.9055\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3878 - categorical_accuracy: 0.9033\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3911 - categorical_accuracy: 0.9056\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3857 - categorical_accuracy: 0.9061\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3789 - categorical_accuracy: 0.9103\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3834 - categorical_accuracy: 0.9091\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3832 - categorical_accuracy: 0.9122\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3748 - categorical_accuracy: 0.9181\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3775 - categorical_accuracy: 0.9135\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3710 - categorical_accuracy: 0.9196\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3763 - categorical_accuracy: 0.9151\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 18s 62ms/step - loss: 0.3733 - categorical_accuracy: 0.9173\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3759 - categorical_accuracy: 0.9169\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3677 - categorical_accuracy: 0.9221\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3684 - categorical_accuracy: 0.9234\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3715 - categorical_accuracy: 0.9192\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3646 - categorical_accuracy: 0.9236\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.3642 - categorical_accuracy: 0.9243\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3658 - categorical_accuracy: 0.9240\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3681 - categorical_accuracy: 0.9261\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3662 - categorical_accuracy: 0.9221\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3629 - categorical_accuracy: 0.9265\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3623 - categorical_accuracy: 0.9245\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3622 - categorical_accuracy: 0.9273\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3654 - categorical_accuracy: 0.9264\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3654 - categorical_accuracy: 0.9258\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3641 - categorical_accuracy: 0.9288\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3606 - categorical_accuracy: 0.9303\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3648 - categorical_accuracy: 0.9269\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3648 - categorical_accuracy: 0.9294\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3629 - categorical_accuracy: 0.9286\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3572 - categorical_accuracy: 0.9331\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3561 - categorical_accuracy: 0.9341\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3545 - categorical_accuracy: 0.9331\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3617 - categorical_accuracy: 0.9286\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3560 - categorical_accuracy: 0.9337\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.3633 - categorical_accuracy: 0.9287\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3547 - categorical_accuracy: 0.9363\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3548 - categorical_accuracy: 0.9354\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3548 - categorical_accuracy: 0.9348\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 16s 57ms/step - loss: 0.3565 - categorical_accuracy: 0.9332\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3578 - categorical_accuracy: 0.9322\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3562 - categorical_accuracy: 0.9332\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3539 - categorical_accuracy: 0.9375\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3546 - categorical_accuracy: 0.9358\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 16s 56ms/step - loss: 0.3477 - categorical_accuracy: 0.9374\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3534 - categorical_accuracy: 0.9395\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.3576 - categorical_accuracy: 0.9319\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3512 - categorical_accuracy: 0.9380\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.3494 - categorical_accuracy: 0.9427\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.3534 - categorical_accuracy: 0.9361\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3514 - categorical_accuracy: 0.9396\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.3518 - categorical_accuracy: 0.9388\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3503 - categorical_accuracy: 0.9417\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3551 - categorical_accuracy: 0.9341\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3514 - categorical_accuracy: 0.9399\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3521 - categorical_accuracy: 0.9372\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3564 - categorical_accuracy: 0.9347\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.3528 - categorical_accuracy: 0.9359\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3495 - categorical_accuracy: 0.9403\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3536 - categorical_accuracy: 0.9362\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3488 - categorical_accuracy: 0.9392\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 17s 58ms/step - loss: 0.3500 - categorical_accuracy: 0.9378\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3527 - categorical_accuracy: 0.9353\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.3478 - categorical_accuracy: 0.9377\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3479 - categorical_accuracy: 0.9412\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3561 - categorical_accuracy: 0.9346\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.3423 - categorical_accuracy: 0.9446\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.3510 - categorical_accuracy: 0.9371\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3461 - categorical_accuracy: 0.9411\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3516 - categorical_accuracy: 0.9392\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3499 - categorical_accuracy: 0.9399\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.3481 - categorical_accuracy: 0.9411\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3441 - categorical_accuracy: 0.9413\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.3473 - categorical_accuracy: 0.9419\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 0.3505 - categorical_accuracy: 0.9362\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.3442 - categorical_accuracy: 0.9431\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.3495 - categorical_accuracy: 0.9387\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.3500 - categorical_accuracy: 0.9416\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.3497 - categorical_accuracy: 0.9397\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 15s 52ms/step - loss: 0.3446 - categorical_accuracy: 0.9412\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3446 - categorical_accuracy: 0.9441\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.3519 - categorical_accuracy: 0.9389\n",
      "Score for fold 5: loss of 0.3301909565925598; categorical_accuracy of 95.92013955116272%\n"
     ]
    }
   ],
   "source": [
    "#CNN MODEL\n",
    "\n",
    "max_features = 11718\n",
    "embedding_dim = 64 #same as URLNet\n",
    "sequence_length = 260\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "inputs = np.concatenate((x_train,x_valid), axis=0)\n",
    "targets = np.concatenate((train_labels, valid_labels), axis=0)\n",
    "\n",
    "#regularizer prevents overfitting\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(max_features +1, embedding_dim, input_length=sequence_length,\\\n",
    "                                        embeddings_regularizer = regularizers.l2(0.0005)))                                    \n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(128,3, activation='relu',\\\n",
    "                                     kernel_regularizer = regularizers.l2(0.0005),\\\n",
    "                                     bias_regularizer = regularizers.l2(0.0005)))                               \n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.5)) #to reduce overfitting\n",
    "\n",
    "    #final classification, 2 classes\n",
    "    model.add(tf.keras.layers.Dense(2, activation='sigmoid',\\\n",
    "                                    kernel_regularizer=regularizers.l2(0.001),\\\n",
    "                                    bias_regularizer=regularizers.l2(0.001),))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer='Nadam', metrics=[\"CategoricalAccuracy\"])\n",
    "    \n",
    "    epochs = 100\n",
    "    # Fit the model using the train and test datasets.\n",
    "    #history = model.fit(x_train, train_labels,validation_data= (x_test,test_labels),epochs=epochs )\n",
    "    history = model.fit(inputs[train], targets[train],\n",
    "                        epochs= epochs ,\n",
    "                        verbose=1)\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4aa2aa-6502-4e52-bffb-e5d32167ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.3239861726760864 - Accuracy: 95.87673544883728%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.32738861441612244 - Accuracy: 96.26736044883728%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.331327885389328 - Accuracy: 95.78993320465088%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.3255639970302582 - Accuracy: 95.61631679534912%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.3301909565925598 - Accuracy: 95.92013955116272%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 95.89409708976746 (+- 0.21369004587257545)\n",
      "> Loss: 0.32769152522087097\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b715be-0b02-486a-b13c-e63f567aa4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7003568410873413,\n",
       "  0.6003673076629639,\n",
       "  0.550531268119812,\n",
       "  0.5197961330413818,\n",
       "  0.4954182207584381,\n",
       "  0.47076544165611267,\n",
       "  0.46447882056236267,\n",
       "  0.4491487145423889,\n",
       "  0.4356113076210022,\n",
       "  0.43428078293800354,\n",
       "  0.4208761155605316,\n",
       "  0.4178127944469452,\n",
       "  0.41123145818710327,\n",
       "  0.411169171333313,\n",
       "  0.40106093883514404,\n",
       "  0.39885255694389343,\n",
       "  0.3941323459148407,\n",
       "  0.3850920796394348,\n",
       "  0.3877650499343872,\n",
       "  0.3910851776599884,\n",
       "  0.38574928045272827,\n",
       "  0.3789204955101013,\n",
       "  0.3833741843700409,\n",
       "  0.3832370340824127,\n",
       "  0.37476783990859985,\n",
       "  0.37751320004463196,\n",
       "  0.37096333503723145,\n",
       "  0.3762844502925873,\n",
       "  0.3733479082584381,\n",
       "  0.37590867280960083,\n",
       "  0.36770114302635193,\n",
       "  0.36843541264533997,\n",
       "  0.37148064374923706,\n",
       "  0.36464905738830566,\n",
       "  0.3642212450504303,\n",
       "  0.3658428490161896,\n",
       "  0.3681264817714691,\n",
       "  0.36624762415885925,\n",
       "  0.36289942264556885,\n",
       "  0.3623206317424774,\n",
       "  0.36215126514434814,\n",
       "  0.36536750197410583,\n",
       "  0.36544859409332275,\n",
       "  0.3641110360622406,\n",
       "  0.36058706045150757,\n",
       "  0.36482805013656616,\n",
       "  0.364812433719635,\n",
       "  0.36291390657424927,\n",
       "  0.35718652606010437,\n",
       "  0.3561335802078247,\n",
       "  0.35450080037117004,\n",
       "  0.3616662919521332,\n",
       "  0.35595518350601196,\n",
       "  0.36327579617500305,\n",
       "  0.35473719239234924,\n",
       "  0.3547525107860565,\n",
       "  0.3547651469707489,\n",
       "  0.3565122187137604,\n",
       "  0.3578415513038635,\n",
       "  0.3561908006668091,\n",
       "  0.3538895845413208,\n",
       "  0.3546094298362732,\n",
       "  0.34772899746894836,\n",
       "  0.35341864824295044,\n",
       "  0.35757511854171753,\n",
       "  0.35121437907218933,\n",
       "  0.3493998050689697,\n",
       "  0.3533617854118347,\n",
       "  0.35143762826919556,\n",
       "  0.35184502601623535,\n",
       "  0.3503463864326477,\n",
       "  0.3551218509674072,\n",
       "  0.3513842821121216,\n",
       "  0.35205405950546265,\n",
       "  0.35639631748199463,\n",
       "  0.35284310579299927,\n",
       "  0.34946590662002563,\n",
       "  0.3535924255847931,\n",
       "  0.3488459885120392,\n",
       "  0.35004591941833496,\n",
       "  0.3526507616043091,\n",
       "  0.3478245735168457,\n",
       "  0.3479442596435547,\n",
       "  0.3560746908187866,\n",
       "  0.3423058092594147,\n",
       "  0.35100057721138,\n",
       "  0.34611260890960693,\n",
       "  0.35157716274261475,\n",
       "  0.34992536902427673,\n",
       "  0.34811732172966003,\n",
       "  0.34407106041908264,\n",
       "  0.3473421633243561,\n",
       "  0.35049915313720703,\n",
       "  0.34416842460632324,\n",
       "  0.3494507670402527,\n",
       "  0.35001131892204285,\n",
       "  0.34967130422592163,\n",
       "  0.34456586837768555,\n",
       "  0.3446003198623657,\n",
       "  0.3519169092178345],\n",
       " 'categorical_accuracy': [0.6293402910232544,\n",
       "  0.7103949785232544,\n",
       "  0.7603081464767456,\n",
       "  0.791015625,\n",
       "  0.8162977695465088,\n",
       "  0.8317057490348816,\n",
       "  0.8402777910232544,\n",
       "  0.8500434160232544,\n",
       "  0.8644748330116272,\n",
       "  0.8671875,\n",
       "  0.8738064169883728,\n",
       "  0.8827040195465088,\n",
       "  0.8842231035232544,\n",
       "  0.8855251669883728,\n",
       "  0.8956162929534912,\n",
       "  0.8958333134651184,\n",
       "  0.8983290195465088,\n",
       "  0.9054904580116272,\n",
       "  0.9033203125,\n",
       "  0.9055989384651184,\n",
       "  0.9061415195465088,\n",
       "  0.9102647304534912,\n",
       "  0.9090712070465088,\n",
       "  0.9122178554534912,\n",
       "  0.9180772304534912,\n",
       "  0.9135199785232544,\n",
       "  0.9195963740348816,\n",
       "  0.9151475429534912,\n",
       "  0.9173176884651184,\n",
       "  0.9168837070465088,\n",
       "  0.9220920205116272,\n",
       "  0.9233940839767456,\n",
       "  0.9191623330116272,\n",
       "  0.9236111044883728,\n",
       "  0.9242621660232544,\n",
       "  0.9240451455116272,\n",
       "  0.9261067509651184,\n",
       "  0.9220920205116272,\n",
       "  0.9265407919883728,\n",
       "  0.9244791865348816,\n",
       "  0.9273003339767456,\n",
       "  0.9264323115348816,\n",
       "  0.92578125,\n",
       "  0.9288194179534912,\n",
       "  0.9303385615348816,\n",
       "  0.9268662929534912,\n",
       "  0.9293619990348816,\n",
       "  0.9286024570465088,\n",
       "  0.9330512285232544,\n",
       "  0.9341362714767456,\n",
       "  0.9330512285232544,\n",
       "  0.9286024570465088,\n",
       "  0.9337022304534912,\n",
       "  0.9287109375,\n",
       "  0.9363064169883728,\n",
       "  0.9354383945465088,\n",
       "  0.9347873330116272,\n",
       "  0.9331597089767456,\n",
       "  0.9321831464767456,\n",
       "  0.9331597089767456,\n",
       "  0.9375,\n",
       "  0.9357638955116272,\n",
       "  0.9373915195465088,\n",
       "  0.939453125,\n",
       "  0.9318576455116272,\n",
       "  0.9380425214767456,\n",
       "  0.9427083134651184,\n",
       "  0.9360893964767456,\n",
       "  0.9395616054534912,\n",
       "  0.9388020634651184,\n",
       "  0.9417317509651184,\n",
       "  0.9341362714767456,\n",
       "  0.9398871660232544,\n",
       "  0.9371744990348816,\n",
       "  0.9346787929534912,\n",
       "  0.9358723759651184,\n",
       "  0.9403212070465088,\n",
       "  0.9361979365348816,\n",
       "  0.9392361044883728,\n",
       "  0.9378255009651184,\n",
       "  0.9353298544883728,\n",
       "  0.9377170205116272,\n",
       "  0.9411892294883728,\n",
       "  0.9345703125,\n",
       "  0.9445529580116272,\n",
       "  0.9370659589767456,\n",
       "  0.9410807490348816,\n",
       "  0.9392361044883728,\n",
       "  0.9398871660232544,\n",
       "  0.9410807490348816,\n",
       "  0.9412977695465088,\n",
       "  0.9419487714767456,\n",
       "  0.9361979365348816,\n",
       "  0.9431423544883728,\n",
       "  0.9386935830116272,\n",
       "  0.9416232705116272,\n",
       "  0.9396701455116272,\n",
       "  0.9411892294883728,\n",
       "  0.9441189169883728,\n",
       "  0.9389106035232544]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc01b7d-a7ab-4284-964d-68598a93d134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(history.history[\\'loss\\'], label=\\' training data\\')\\nplt.plot(history.history[\\'val_loss\\'], label=\\'validation data\\')\\nplt.title(\\'Loss for Text Classification\\')\\nplt.ylabel(\\'Loss value\\')\\nplt.xlabel(\\'No. epoch\\')\\nplt.legend(loc=\"upper left\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(history.history['loss'], label=' training data')\n",
    "plt.plot(history.history['val_loss'], label='validation data')\n",
    "plt.title('Loss for Text Classification')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6006641d-83c9-425e-b84d-9451bbd391d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(history.history[\\'categorical_accuracy\\'], label=\\' (training data)\\')\\nplt.plot(history.history[\\'val_categorical_accuracy\\'], label=\\'CategoricalCrossentropy (validation data)\\')\\nplt.title(\\'CategoricalAccuracy for Text Classification\\')\\nplt.ylabel(\\'CategoricalAccuracy value\\')\\nplt.xlabel(\\'No. epoch\\')\\nplt.legend(loc=\"upper left\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(history.history['categorical_accuracy'], label=' (training data)')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='CategoricalCrossentropy (validation data)')\n",
    "plt.title('CategoricalAccuracy for Text Classification')\n",
    "plt.ylabel('CategoricalAccuracy value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d38779-c46b-4600-aaa7-752e4d5f6120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\URLchar\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\URLchar\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar') \n",
    "json_string = URLchar.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c07f08ee-072a-494b-9587-97c719629c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar\\\\URLchar.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093fad61-1d01-4441-af0d-3e758dcfd3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reload model\n",
    "\n",
    "new_model = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aa4ad50-70d5-491a-86a6-c0ec45ac1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar\\\\URLchar.json') as json_file:\n",
    "    json_string = json.load(json_file)\n",
    "tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0593ab06-c7f7-45ad-99d3-0bb97114bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_11248\\2077557873.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test  = np.array( tokenizer1.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test  = np.array( tokenizer1.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "285b5d0c-c6cc-4ad3-851c-d0dda819352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 6ms/step\n",
      "[[0.99622256 0.00377741]\n",
      " [0.9815708  0.01842912]\n",
      " [0.7696982  0.23030218]\n",
      " ...\n",
      " [0.8019059  0.19809413]\n",
      " [0.9904026  0.00959739]\n",
      " [0.9476664  0.05233338]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on test  data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d03231-1179-4974-8e41-a79d81b9e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake']= predict_results\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '0'),0,test_data.pred_fake)\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '1'),1,test_data.pred_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a747c5-d56b-41b2-b46f-ddef6c577fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e92601-5e63-4df0-b3b3-6b2fdcb5902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: pred_fake, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake']))\n",
    "test_data['pred_fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f32efb08-5b28-4e69-8718-4bd1d01411ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1429\n",
      "           1       0.73      0.73      0.73       184\n",
      "\n",
      "    accuracy                           0.94      1613\n",
      "   macro avg       0.85      0.85      0.85      1613\n",
      "weighted avg       0.94      0.94      0.94      1613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ed79082-76d1-4346-932c-e970cd4fee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precisionscore = precision_score(y_test, new_model.predict(x_test))\\naccuracyscore = accuracy_score(y_test, new_model.predict(x_test))\\nrecallscore = recall_score(y_test, new_model.predict(x_test))\\nf1score = f1_score(y_test, new_model.predict(x_test))\\ncm = confusion_matrix(y_test, new_model.predict(x_test))\\n\\nprint(precisionscore, accuracyscore, recallscore, f1score, cm)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"precisionscore = precision_score(y_test, new_model.predict(x_test))\n",
    "accuracyscore = accuracy_score(y_test, new_model.predict(x_test))\n",
    "recallscore = recall_score(y_test, new_model.predict(x_test))\n",
    "f1score = f1_score(y_test, new_model.predict(x_test))\n",
    "cm = confusion_matrix(y_test, new_model.predict(x_test))\n",
    "\n",
    "print(precisionscore, accuracyscore, recallscore, f1score, cm)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9202e-a347-4243-a327-1e3432c9e19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac01755-1aa1-41d5-8069-c8a0b390ea45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8d717-8329-4a77-bac7-e50dff1e8bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
