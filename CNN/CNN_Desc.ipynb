{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b88e8e-e454-49d2-ad8e-8e63defc99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%%script C:\\Users\\Jan Catherine\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6882c84-4ec7-4025-862c-e30f906994de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57500b2d-3257-4427-9f33-9d055fc284e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../Data_Collection_02/02_Preprocessing/05_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8863d932-63b8-4c2b-a9bf-cc584f2b6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5f248c-54b6-4365-af00-0637fb458e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Activation, Flatten\\nfrom keras.layers import Convolution2D, MaxPooling2D\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd\\nimport numpy as np\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61db8ea8-a355-4d58-b625-4013889267b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31ffad0-8c40-4997-91a8-c775cb33d04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "-------Train data--------\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "11520\n",
      "-------------------------\n",
      "-------Test data--------\n",
      "0    1429\n",
      "1     184\n",
      "Name: Fake, dtype: int64\n",
      "1613\n",
      "-------------------------\n",
      "Train Max Length :42\n",
      "Test Max Sentence Length :38\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('01_Description_Train.csv', encoding='latin-1')\n",
    "testdata = pd.read_csv('01_Description_Test.csv', encoding='latin-1')\n",
    "\n",
    "train_data = dataset\n",
    "test_data = testdata\n",
    "\n",
    "#Oversampling\n",
    "count_class_0, count_class_1 = train_data.Fake.value_counts()\n",
    "\n",
    "df_class_0 = train_data[train_data['Fake'] == 0]\n",
    "df_class_1 = train_data[train_data['Fake'] == 1]\n",
    "\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "df_test_over = df_test_over.reset_index(drop=True)\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Fake.value_counts())\n",
    "\n",
    "train_data = df_test_over\n",
    "#train_data['Description'] = df_test_over['Description']\n",
    "#train_data['Fake'] = df_test_over['Fake']\n",
    "\n",
    "print(train_data.Fake.value_counts())\n",
    "\n",
    "train_data.dropna(axis=0, how ='any', inplace=True)\n",
    "train_data['Num_words_desc'] = train_data['Description'].apply(lambda x:len(str(x).split()))\n",
    "#train_data['Num_words_desc'] = train_data['Description'].apply(lambda x:len(str(x).split()))\n",
    "print('-------Train data--------')\n",
    "print(train_data['Fake'].value_counts())\n",
    "print(len(train_data))\n",
    "print('-------------------------')\n",
    "\n",
    "max_train_desc_length  = train_data['Num_words_desc'].max()\n",
    "#max_train_desc_length  = train_data['Num_words_desc'].max()\n",
    "\n",
    "\n",
    "test_data.dropna(axis = 0, how ='any',inplace=True) \n",
    "test_data['Num_words_desc'] = test_data['Description'].apply(lambda x:len(str(x).split())) \n",
    "\n",
    "max_test_desc_length  = test_data['Num_words_desc'].max()\n",
    "\n",
    "print('-------Test data--------')\n",
    "print(test_data['Fake'].value_counts())\n",
    "print(len(test_data))\n",
    "print('-------------------------')\n",
    "\n",
    "print('Train Max Length :'+str(max_train_desc_length))\n",
    "print('Test Max Sentence Length :'+str(max_test_desc_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a2bbef-3563-46e8-a7b6-960806b53caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Num_words_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enemy virus ? ongoing war COVID19 exact opposi...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average Chinese population spent around seven ...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronado Crime Report : Larceny Assault Deadly...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>note size SARSCoV2 approximately nm times smal...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worsening economic outlook worsening economic ...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  Fake  Num_words_desc\n",
       "0  enemy virus ? ongoing war COVID19 exact opposi...     0              13\n",
       "1  average Chinese population spent around seven ...     0              18\n",
       "2  Coronado Crime Report : Larceny Assault Deadly...     0              18\n",
       "3  note size SARSCoV2 approximately nm times smal...     0              11\n",
       "4  worsening economic outlook worsening economic ...     0              26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21264bed-6b54-438e-b82e-8fe0913d7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17, 36, 35, 7555]]\n"
     ]
    }
   ],
   "source": [
    "num_words = 20000\n",
    "\n",
    "\n",
    "Desc = Tokenizer(num_words=num_words, oov_token=\"unk\")\n",
    "Desc.fit_on_texts(train_data['Description'].tolist())\n",
    "\n",
    "print(str(Desc.texts_to_sequences(['5G Global bill airfare'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fbc624-d2a4-41b1-be0a-e7683b4d2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:9216\n",
      "Class distributionCounter({0: 4608, 1: 4608})\n",
      "Valid data len:2304\n",
      "Class distributionCounter({1: 1152, 0: 1152})\n",
      "[ 4095  2465 12502  7992  3467  1455   566    13    39 12503  6377   366\n",
      "   558 12504 12505  2708   817  4731 12506  7541   532  3898  3245 12507\n",
      "  5022  7508  5601  3245 12508  5676     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_10172\\2521163543.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array( Desc.texts_to_sequences(X_train) )\n",
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_10172\\2521163543.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_valid = np.array( Desc.texts_to_sequences(X_valid) )\n",
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_10172\\2521163543.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test  = np.array( Desc.texts_to_sequences(test_data['Description'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data['Description'].tolist(),\\\n",
    "                                                      train_data['Fake'].tolist(),\\\n",
    "                                                      test_size=0.2,\\\n",
    "                                                      stratify = train_data['Fake'].tolist(),\\\n",
    "                                                      random_state=0)\n",
    "\n",
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution'+str(Counter(y_train)))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution'+ str(Counter(y_valid)))\n",
    "\n",
    "x_train = np.array( Desc.texts_to_sequences(X_train) )\n",
    "x_valid = np.array( Desc.texts_to_sequences(X_valid) )\n",
    "x_test  = np.array( Desc.texts_to_sequences(test_data['Description'].tolist()) )\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=50)\n",
    "x_valid = pad_sequences(x_valid, padding='post', maxlen=50)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=50)\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_labels = le.fit_transform(y_train)\n",
    "train_labels = np.asarray( tf.keras.utils.to_categorical(train_labels, 2))\n",
    "#print(train_labels)\n",
    "valid_labels = le.transform(y_valid)\n",
    "valid_labels = np.asarray( tf.keras.utils.to_categorical(valid_labels, 2))\n",
    "\n",
    "\n",
    "test_labels = le.transform(test_data['Fake'].tolist())\n",
    "test_labels = np.asarray(tf.keras.utils.to_categorical(test_labels, 2))\n",
    "list(le.classes_)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,train_labels))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0143d15f-85f2-4690-8a64-e438f3f4656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Num_words_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hepa filters remove even extremely tiny partic...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CORONAVIRUS known COVID19 swept north Italy we...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phones Gadgets Gaming Motors Motors News Revie...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First Trump s wink debunked conspiracy theorie...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting COVID19 testing site please call ahea...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  Fake  Num_words_desc\n",
       "0  Hepa filters remove even extremely tiny partic...     0              12\n",
       "1  CORONAVIRUS known COVID19 swept north Italy we...     0              17\n",
       "2  Phones Gadgets Gaming Motors Motors News Revie...     0              18\n",
       "3  First Trump s wink debunked conspiracy theorie...     0              16\n",
       "4  visiting COVID19 testing site please call ahea...     0              15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bf38b8-3b43-49a7-a1b8-90da4888318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Train dataset ====\n",
      "tf.Tensor(\n",
      "[ 4095  2465 12502  7992  3467  1455   566    13    39 12503  6377   366\n",
      "   558 12504 12505  2708   817  4731 12506  7541   532  3898  3245 12507\n",
      "  5022  7508  5601  3245 12508  5676     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[1306  532  143    3  215  169  869  477 1946 5112   85 5113  230    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   22 12367  3242  8043 12368 12369   152   182  2871 12370  7998  1843\n",
      "  4071   604 12371    23  5263     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "======Validation dataset ====\n",
      "tf.Tensor(\n",
      "[1478  476  848    5   52    3  438   14    2   28  287   51   10  269\n",
      "   81    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int32) tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  66    2  816   11  194  187   21  219   31   55  346   37   11   25\n",
      "    2   33   72    9   28   10 1705 1246 3342 3450    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int32) tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 189 9861 9862  230   32 1835    2 6735 9863 3225 1295 5647  832 1146\n",
      "  333  979  234    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "======Test dataset ====\n",
      "tf.Tensor(\n",
      "[1855 1007 2932   63  669 1506   61  163   22   19  163   23    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   2  104    3 6589  356   16 1849   25    6 1213  233 1044 1250   15\n",
      "   16 5981    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  517 12044     1     1     1    56  5174  1359     1 10255   762  7809\n",
      " 11252 11253     7     2   108  4879     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0], shape=(50,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "print('======Train dataset ====')\n",
    "for value,label in train_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break\n",
    "count =0\n",
    "print('======Validation dataset ====')\n",
    "for value,label in valid_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break\n",
    "count = 0\n",
    "print('======Test dataset ====')\n",
    "for value,label in test_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dc6838-cfe5-4647-8591-125720406e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 13s 40ms/step - loss: 0.6144 - categorical_accuracy: 0.7708\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.2657 - categorical_accuracy: 0.9589\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1946 - categorical_accuracy: 0.9880\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1725 - categorical_accuracy: 0.9953\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1683 - categorical_accuracy: 0.9958\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1643 - categorical_accuracy: 0.9962\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1657 - categorical_accuracy: 0.9963\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1627 - categorical_accuracy: 0.9954\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1632 - categorical_accuracy: 0.9962\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1604 - categorical_accuracy: 0.9971\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1614 - categorical_accuracy: 0.9963\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1609 - categorical_accuracy: 0.9972\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1588 - categorical_accuracy: 0.9971\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1606 - categorical_accuracy: 0.9974\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1571 - categorical_accuracy: 0.9975\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1562 - categorical_accuracy: 0.9978\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1579 - categorical_accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1563 - categorical_accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1550 - categorical_accuracy: 0.9983\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1548 - categorical_accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1562 - categorical_accuracy: 0.9973\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1539 - categorical_accuracy: 0.9987\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1547 - categorical_accuracy: 0.9973\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1549 - categorical_accuracy: 0.9970\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1543 - categorical_accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1522 - categorical_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1522 - categorical_accuracy: 0.9987\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1515 - categorical_accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1521 - categorical_accuracy: 0.9980\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1516 - categorical_accuracy: 0.9975\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1511 - categorical_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1502 - categorical_accuracy: 0.9984\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1486 - categorical_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1492 - categorical_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1483 - categorical_accuracy: 0.9986\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1485 - categorical_accuracy: 0.9982\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.1482 - categorical_accuracy: 0.9982\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1488 - categorical_accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1476 - categorical_accuracy: 0.9986\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1475 - categorical_accuracy: 0.9987\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1477 - categorical_accuracy: 0.9986\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1468 - categorical_accuracy: 0.9988\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1475 - categorical_accuracy: 0.9980\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1473 - categorical_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1460 - categorical_accuracy: 0.9987\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1468 - categorical_accuracy: 0.9985\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1456 - categorical_accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1468 - categorical_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1453 - categorical_accuracy: 0.9990\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1449 - categorical_accuracy: 0.9985\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1453 - categorical_accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1452 - categorical_accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1457 - categorical_accuracy: 0.9983\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1444 - categorical_accuracy: 0.9986\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1453 - categorical_accuracy: 0.9989\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1450 - categorical_accuracy: 0.9988\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.1437 - categorical_accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1451 - categorical_accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1446 - categorical_accuracy: 0.9983\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1446 - categorical_accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1441 - categorical_accuracy: 0.9988\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1458 - categorical_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1445 - categorical_accuracy: 0.9986\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1444 - categorical_accuracy: 0.9988\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1448 - categorical_accuracy: 0.9986\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1438 - categorical_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1449 - categorical_accuracy: 0.9985\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1442 - categorical_accuracy: 0.9987\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1433 - categorical_accuracy: 0.9991\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1446 - categorical_accuracy: 0.9983\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1444 - categorical_accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1434 - categorical_accuracy: 0.9989\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1439 - categorical_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1433 - categorical_accuracy: 0.9990\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1439 - categorical_accuracy: 0.9989\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1438 - categorical_accuracy: 0.9990\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1438 - categorical_accuracy: 0.9989\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1448 - categorical_accuracy: 0.9986\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1439 - categorical_accuracy: 0.9988\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1433 - categorical_accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.1431 - categorical_accuracy: 0.9991\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1441 - categorical_accuracy: 0.9983\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1436 - categorical_accuracy: 0.9989\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1433 - categorical_accuracy: 0.9988\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1427 - categorical_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1437 - categorical_accuracy: 0.9988\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1429 - categorical_accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1433 - categorical_accuracy: 0.9987\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1431 - categorical_accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1435 - categorical_accuracy: 0.9986\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1423 - categorical_accuracy: 0.9988\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1429 - categorical_accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.1433 - categorical_accuracy: 0.9989\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1436 - categorical_accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1426 - categorical_accuracy: 0.9992\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1424 - categorical_accuracy: 0.9991\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1424 - categorical_accuracy: 0.9989\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1436 - categorical_accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.1422 - categorical_accuracy: 0.9989\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1414 - categorical_accuracy: 0.9991\n",
      "Score for fold 1: loss of 0.18805181980133057; categorical_accuracy of 97.91666865348816%\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 37ms/step - loss: 0.6111 - categorical_accuracy: 0.7730\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.2758 - categorical_accuracy: 0.9543\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.2017 - categorical_accuracy: 0.9850\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1768 - categorical_accuracy: 0.9929\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1695 - categorical_accuracy: 0.9944\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1681 - categorical_accuracy: 0.9949\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1638 - categorical_accuracy: 0.9959\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1647 - categorical_accuracy: 0.9947\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1626 - categorical_accuracy: 0.9964\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1594 - categorical_accuracy: 0.9977\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1629 - categorical_accuracy: 0.9952\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1616 - categorical_accuracy: 0.9975\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1612 - categorical_accuracy: 0.9967\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1591 - categorical_accuracy: 0.9983\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1606 - categorical_accuracy: 0.9964\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1572 - categorical_accuracy: 0.9975\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1585 - categorical_accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1560 - categorical_accuracy: 0.9979\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.1592 - categorical_accuracy: 0.9969\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.1561 - categorical_accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1553 - categorical_accuracy: 0.9982\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1570 - categorical_accuracy: 0.9972\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1556 - categorical_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1546 - categorical_accuracy: 0.9987\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1539 - categorical_accuracy: 0.9977\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 15s 50ms/step - loss: 0.1549 - categorical_accuracy: 0.9974\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1542 - categorical_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1532 - categorical_accuracy: 0.9986\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1530 - categorical_accuracy: 0.9982\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1533 - categorical_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1522 - categorical_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1514 - categorical_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1511 - categorical_accuracy: 0.9985\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1510 - categorical_accuracy: 0.9978\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1504 - categorical_accuracy: 0.9985\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1521 - categorical_accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1503 - categorical_accuracy: 0.9985\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1503 - categorical_accuracy: 0.9986\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1501 - categorical_accuracy: 0.9982\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1489 - categorical_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1484 - categorical_accuracy: 0.9990\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1502 - categorical_accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1500 - categorical_accuracy: 0.9986\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1491 - categorical_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1507 - categorical_accuracy: 0.9978\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1480 - categorical_accuracy: 0.9987\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1485 - categorical_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1484 - categorical_accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1481 - categorical_accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1481 - categorical_accuracy: 0.9989\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1486 - categorical_accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1473 - categorical_accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1468 - categorical_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1464 - categorical_accuracy: 0.9993\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1465 - categorical_accuracy: 0.9993\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1467 - categorical_accuracy: 0.9983\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1465 - categorical_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1469 - categorical_accuracy: 0.9986\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1467 - categorical_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1472 - categorical_accuracy: 0.9987\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1465 - categorical_accuracy: 0.9987\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1459 - categorical_accuracy: 0.9989\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1456 - categorical_accuracy: 0.9991\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1461 - categorical_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1465 - categorical_accuracy: 0.9982\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1460 - categorical_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1453 - categorical_accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1460 - categorical_accuracy: 0.9985\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1445 - categorical_accuracy: 0.9993\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1446 - categorical_accuracy: 0.9993\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1452 - categorical_accuracy: 0.9991\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1449 - categorical_accuracy: 0.9988\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1450 - categorical_accuracy: 0.9990\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1449 - categorical_accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1439 - categorical_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1440 - categorical_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1447 - categorical_accuracy: 0.9990\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1452 - categorical_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1443 - categorical_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1443 - categorical_accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1439 - categorical_accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1437 - categorical_accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1440 - categorical_accuracy: 0.9992\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1438 - categorical_accuracy: 0.9989\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1441 - categorical_accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1429 - categorical_accuracy: 0.9990\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1433 - categorical_accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1438 - categorical_accuracy: 0.9988\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1443 - categorical_accuracy: 0.9986\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1433 - categorical_accuracy: 0.9988\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1430 - categorical_accuracy: 0.9992\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1435 - categorical_accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1425 - categorical_accuracy: 0.9991\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1434 - categorical_accuracy: 0.9990\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1429 - categorical_accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1423 - categorical_accuracy: 0.9991\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1434 - categorical_accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1420 - categorical_accuracy: 0.9991\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1427 - categorical_accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1423 - categorical_accuracy: 0.9991\n",
      "Score for fold 2: loss of 0.20185264945030212; categorical_accuracy of 97.69965410232544%\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 38ms/step - loss: 0.6101 - categorical_accuracy: 0.7755\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.2776 - categorical_accuracy: 0.9543\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1963 - categorical_accuracy: 0.9874\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1747 - categorical_accuracy: 0.9934\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1697 - categorical_accuracy: 0.9949\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1678 - categorical_accuracy: 0.9952\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1637 - categorical_accuracy: 0.9956\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1645 - categorical_accuracy: 0.9963\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1619 - categorical_accuracy: 0.9970\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1628 - categorical_accuracy: 0.9964\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1620 - categorical_accuracy: 0.9978\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1599 - categorical_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1587 - categorical_accuracy: 0.9978\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1573 - categorical_accuracy: 0.9982\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1612 - categorical_accuracy: 0.9962\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1585 - categorical_accuracy: 0.9972\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1573 - categorical_accuracy: 0.9978\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1571 - categorical_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1566 - categorical_accuracy: 0.9978\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1575 - categorical_accuracy: 0.9977\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1540 - categorical_accuracy: 0.9986\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1556 - categorical_accuracy: 0.9974\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1557 - categorical_accuracy: 0.9983\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1549 - categorical_accuracy: 0.9984\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1531 - categorical_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1537 - categorical_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1529 - categorical_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1519 - categorical_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1526 - categorical_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1524 - categorical_accuracy: 0.9982\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1524 - categorical_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1510 - categorical_accuracy: 0.9988\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.1521 - categorical_accuracy: 0.9987\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1498 - categorical_accuracy: 0.9991\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1497 - categorical_accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1505 - categorical_accuracy: 0.9989\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1507 - categorical_accuracy: 0.9985\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1496 - categorical_accuracy: 0.9986\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1489 - categorical_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 15s 53ms/step - loss: 0.1487 - categorical_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1505 - categorical_accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1487 - categorical_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1474 - categorical_accuracy: 0.9992\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 15s 50ms/step - loss: 0.1482 - categorical_accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 16s 55ms/step - loss: 0.1488 - categorical_accuracy: 0.9988\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1478 - categorical_accuracy: 0.9989\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1476 - categorical_accuracy: 0.9991\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1468 - categorical_accuracy: 0.9987\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1472 - categorical_accuracy: 0.9986\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.1473 - categorical_accuracy: 0.9982\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1470 - categorical_accuracy: 0.9988\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1463 - categorical_accuracy: 0.9990\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1474 - categorical_accuracy: 0.9986\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1462 - categorical_accuracy: 0.9993\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1472 - categorical_accuracy: 0.9987\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1469 - categorical_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1466 - categorical_accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1458 - categorical_accuracy: 0.9986\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1460 - categorical_accuracy: 0.9991\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1461 - categorical_accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1451 - categorical_accuracy: 0.9989\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1444 - categorical_accuracy: 0.9991\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1457 - categorical_accuracy: 0.9990\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1450 - categorical_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1459 - categorical_accuracy: 0.9989\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1446 - categorical_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1446 - categorical_accuracy: 0.9988\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1447 - categorical_accuracy: 0.9986\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1455 - categorical_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1436 - categorical_accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1442 - categorical_accuracy: 0.9992\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1441 - categorical_accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1452 - categorical_accuracy: 0.9993\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1434 - categorical_accuracy: 0.9991\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.1450 - categorical_accuracy: 0.9990\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1441 - categorical_accuracy: 0.9995\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.1429 - categorical_accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1444 - categorical_accuracy: 0.9995\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1435 - categorical_accuracy: 0.9991\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1434 - categorical_accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1437 - categorical_accuracy: 0.9988\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1433 - categorical_accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1435 - categorical_accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1425 - categorical_accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1429 - categorical_accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1426 - categorical_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1432 - categorical_accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1440 - categorical_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1418 - categorical_accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1417 - categorical_accuracy: 0.9991\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1416 - categorical_accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1423 - categorical_accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1429 - categorical_accuracy: 0.9991\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1414 - categorical_accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1425 - categorical_accuracy: 0.9991\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1423 - categorical_accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1423 - categorical_accuracy: 0.9995\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1423 - categorical_accuracy: 0.9986\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1421 - categorical_accuracy: 0.9992\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1414 - categorical_accuracy: 0.9992\n",
      "Score for fold 3: loss of 0.18971017003059387; categorical_accuracy of 97.78645634651184%\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 14s 44ms/step - loss: 0.6031 - categorical_accuracy: 0.7903\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.2680 - categorical_accuracy: 0.9603\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1975 - categorical_accuracy: 0.9867\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1758 - categorical_accuracy: 0.9929\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1692 - categorical_accuracy: 0.9959\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1656 - categorical_accuracy: 0.9960\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1638 - categorical_accuracy: 0.9966\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1633 - categorical_accuracy: 0.9963\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1627 - categorical_accuracy: 0.9964\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1590 - categorical_accuracy: 0.9982\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1617 - categorical_accuracy: 0.9954\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1609 - categorical_accuracy: 0.9978\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1602 - categorical_accuracy: 0.9970\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 11s 36ms/step - loss: 0.1599 - categorical_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1594 - categorical_accuracy: 0.9971\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1572 - categorical_accuracy: 0.9983\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1570 - categorical_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1569 - categorical_accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1586 - categorical_accuracy: 0.9960\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1571 - categorical_accuracy: 0.9982\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1547 - categorical_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1556 - categorical_accuracy: 0.9978\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1556 - categorical_accuracy: 0.9982\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1539 - categorical_accuracy: 0.9983\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1544 - categorical_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1553 - categorical_accuracy: 0.9974\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 11s 36ms/step - loss: 0.1527 - categorical_accuracy: 0.9983\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1533 - categorical_accuracy: 0.9975\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1531 - categorical_accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1512 - categorical_accuracy: 0.9985\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1512 - categorical_accuracy: 0.9977\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1515 - categorical_accuracy: 0.9978\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1505 - categorical_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1503 - categorical_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1493 - categorical_accuracy: 0.9986\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1494 - categorical_accuracy: 0.9989\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1497 - categorical_accuracy: 0.9982\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1490 - categorical_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1484 - categorical_accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1482 - categorical_accuracy: 0.9984\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1475 - categorical_accuracy: 0.9987\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1472 - categorical_accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1479 - categorical_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1466 - categorical_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1478 - categorical_accuracy: 0.9985\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1473 - categorical_accuracy: 0.9985\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1457 - categorical_accuracy: 0.9991\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1464 - categorical_accuracy: 0.9980\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1463 - categorical_accuracy: 0.9988\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1450 - categorical_accuracy: 0.9987\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1464 - categorical_accuracy: 0.9988\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1457 - categorical_accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1453 - categorical_accuracy: 0.9989\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1457 - categorical_accuracy: 0.9990\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1446 - categorical_accuracy: 0.9989\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1450 - categorical_accuracy: 0.9988\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1456 - categorical_accuracy: 0.9983\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1452 - categorical_accuracy: 0.9986\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1438 - categorical_accuracy: 0.9987\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1444 - categorical_accuracy: 0.9988\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1455 - categorical_accuracy: 0.9989\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1445 - categorical_accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1442 - categorical_accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1446 - categorical_accuracy: 0.9989\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1444 - categorical_accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1434 - categorical_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1439 - categorical_accuracy: 0.9986\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1439 - categorical_accuracy: 0.9988\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1438 - categorical_accuracy: 0.9988\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1434 - categorical_accuracy: 0.9989\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1428 - categorical_accuracy: 0.9989\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1441 - categorical_accuracy: 0.9985\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1441 - categorical_accuracy: 0.9986\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1433 - categorical_accuracy: 0.9991\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1438 - categorical_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1424 - categorical_accuracy: 0.9988\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1420 - categorical_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1427 - categorical_accuracy: 0.9988\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1428 - categorical_accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1430 - categorical_accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1436 - categorical_accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1428 - categorical_accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1425 - categorical_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1431 - categorical_accuracy: 0.9988\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1418 - categorical_accuracy: 0.9990\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1420 - categorical_accuracy: 0.9990\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1421 - categorical_accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1422 - categorical_accuracy: 0.9989\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1426 - categorical_accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1417 - categorical_accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1423 - categorical_accuracy: 0.9986\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1419 - categorical_accuracy: 0.9991\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1425 - categorical_accuracy: 0.9988\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1418 - categorical_accuracy: 0.9991\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1412 - categorical_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1423 - categorical_accuracy: 0.9990\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1422 - categorical_accuracy: 0.9992\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1418 - categorical_accuracy: 0.9990\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1426 - categorical_accuracy: 0.9985\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1417 - categorical_accuracy: 0.9991\n",
      "Score for fold 4: loss of 0.18364185094833374; categorical_accuracy of 98.046875%\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 36ms/step - loss: 0.6029 - categorical_accuracy: 0.7923\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.2657 - categorical_accuracy: 0.9602\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1950 - categorical_accuracy: 0.9885\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1771 - categorical_accuracy: 0.9938\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1700 - categorical_accuracy: 0.9949\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1673 - categorical_accuracy: 0.9951\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1645 - categorical_accuracy: 0.9961\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1648 - categorical_accuracy: 0.9963\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1642 - categorical_accuracy: 0.9962\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1638 - categorical_accuracy: 0.9967\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1628 - categorical_accuracy: 0.9965\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1610 - categorical_accuracy: 0.9970\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1632 - categorical_accuracy: 0.9973\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1609 - categorical_accuracy: 0.9973\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1603 - categorical_accuracy: 0.9958\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1599 - categorical_accuracy: 0.9971\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1600 - categorical_accuracy: 0.9969\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1580 - categorical_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1583 - categorical_accuracy: 0.9971\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1584 - categorical_accuracy: 0.9967\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 11s 36ms/step - loss: 0.1562 - categorical_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1581 - categorical_accuracy: 0.9969\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1564 - categorical_accuracy: 0.9972\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1559 - categorical_accuracy: 0.9972\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1552 - categorical_accuracy: 0.9971\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1533 - categorical_accuracy: 0.9978\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1550 - categorical_accuracy: 0.9970\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1540 - categorical_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1526 - categorical_accuracy: 0.9978\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1515 - categorical_accuracy: 0.9982\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1526 - categorical_accuracy: 0.9982\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1522 - categorical_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.1522 - categorical_accuracy: 0.9985\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1499 - categorical_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1515 - categorical_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1512 - categorical_accuracy: 0.9983\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1503 - categorical_accuracy: 0.9982\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1507 - categorical_accuracy: 0.9983\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1486 - categorical_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1492 - categorical_accuracy: 0.9986\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1484 - categorical_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1498 - categorical_accuracy: 0.9978\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1491 - categorical_accuracy: 0.9985\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1482 - categorical_accuracy: 0.9979\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1483 - categorical_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1469 - categorical_accuracy: 0.9980\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1474 - categorical_accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1482 - categorical_accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1471 - categorical_accuracy: 0.9987\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1477 - categorical_accuracy: 0.9982\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1463 - categorical_accuracy: 0.9987\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1475 - categorical_accuracy: 0.9984\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1477 - categorical_accuracy: 0.9977\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1468 - categorical_accuracy: 0.9989\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1464 - categorical_accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1466 - categorical_accuracy: 0.9982\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1461 - categorical_accuracy: 0.9986\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1459 - categorical_accuracy: 0.9982\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1460 - categorical_accuracy: 0.9985\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1453 - categorical_accuracy: 0.9984\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1440 - categorical_accuracy: 0.9987\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1449 - categorical_accuracy: 0.9986\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1460 - categorical_accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1447 - categorical_accuracy: 0.9980\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1450 - categorical_accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1442 - categorical_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1453 - categorical_accuracy: 0.9987\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1452 - categorical_accuracy: 0.9982\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1441 - categorical_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1448 - categorical_accuracy: 0.9984\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1440 - categorical_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1442 - categorical_accuracy: 0.9989\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 12s 41ms/step - loss: 0.1442 - categorical_accuracy: 0.9989\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1445 - categorical_accuracy: 0.9988\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1442 - categorical_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1438 - categorical_accuracy: 0.9986\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1445 - categorical_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1438 - categorical_accuracy: 0.9984\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1447 - categorical_accuracy: 0.9977\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1444 - categorical_accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1429 - categorical_accuracy: 0.9989\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1427 - categorical_accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1431 - categorical_accuracy: 0.9985\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1435 - categorical_accuracy: 0.9985\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1447 - categorical_accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1427 - categorical_accuracy: 0.9986\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1423 - categorical_accuracy: 0.9987\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1435 - categorical_accuracy: 0.9987\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.1433 - categorical_accuracy: 0.9984\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1438 - categorical_accuracy: 0.9986\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1429 - categorical_accuracy: 0.9987\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1436 - categorical_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1441 - categorical_accuracy: 0.9989\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1422 - categorical_accuracy: 0.9988\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1429 - categorical_accuracy: 0.9986\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 12s 43ms/step - loss: 0.1433 - categorical_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1436 - categorical_accuracy: 0.9987\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1427 - categorical_accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1426 - categorical_accuracy: 0.9988\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1427 - categorical_accuracy: 0.9989\n",
      "Score for fold 5: loss of 0.206312358379364; categorical_accuracy of 97.22222089767456%\n"
     ]
    }
   ],
   "source": [
    "#CNN MODEL\n",
    "\n",
    "max_features = 20000\n",
    "embedding_dim = 64 #same as URLNet\n",
    "sequence_length = 50\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "inputs = np.concatenate((x_train,x_valid), axis=0)\n",
    "targets = np.concatenate((train_labels, valid_labels), axis=0)\n",
    "\n",
    "#regularizer prevents overfitting\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(max_features +1, embedding_dim, input_length=sequence_length,\\\n",
    "                                        embeddings_regularizer = regularizers.l2(0.0005)))                                    \n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(128,3, activation='relu',\\\n",
    "                                     kernel_regularizer = regularizers.l2(0.0005),\\\n",
    "                                     bias_regularizer = regularizers.l2(0.0005)))                               \n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.5)) #to reduce overfitting\n",
    "\n",
    "    #final classification, 2 classes\n",
    "    model.add(tf.keras.layers.Dense(2, activation='sigmoid',\\\n",
    "                                    kernel_regularizer=regularizers.l2(0.001),\\\n",
    "                                    bias_regularizer=regularizers.l2(0.001),))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer='Nadam', metrics=[\"CategoricalAccuracy\"])\n",
    "    \n",
    "    epochs = 100\n",
    "    # Fit the model using the train and test datasets.\n",
    "    #history = model.fit(x_train, train_labels,validation_data= (x_test,test_labels),epochs=epochs )\n",
    "    history = model.fit(inputs[train], targets[train], epochs= epochs,verbose=1)\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4aa2aa-6502-4e52-bffb-e5d32167ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.18805181980133057 - Accuracy: 97.91666865348816%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.20185264945030212 - Accuracy: 97.69965410232544%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.18971017003059387 - Accuracy: 97.78645634651184%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.18364185094833374 - Accuracy: 98.046875%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.206312358379364 - Accuracy: 97.22222089767456%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 97.734375 (+- 0.28181804698090274)\n",
      "> Loss: 0.19391376972198487\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b715be-0b02-486a-b13c-e63f567aa4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6028990745544434,\n",
       "  0.26574674248695374,\n",
       "  0.1950431764125824,\n",
       "  0.17707140743732452,\n",
       "  0.17004930973052979,\n",
       "  0.16725461184978485,\n",
       "  0.16452595591545105,\n",
       "  0.1647566854953766,\n",
       "  0.16419760882854462,\n",
       "  0.1638253629207611,\n",
       "  0.16277822852134705,\n",
       "  0.16097724437713623,\n",
       "  0.16317540407180786,\n",
       "  0.16093796491622925,\n",
       "  0.16028402745723724,\n",
       "  0.15993982553482056,\n",
       "  0.1600058674812317,\n",
       "  0.1579657942056656,\n",
       "  0.15829187631607056,\n",
       "  0.1583680659532547,\n",
       "  0.1562432050704956,\n",
       "  0.15808631479740143,\n",
       "  0.15636856853961945,\n",
       "  0.1559147834777832,\n",
       "  0.1552429497241974,\n",
       "  0.1533261090517044,\n",
       "  0.15504933893680573,\n",
       "  0.15396852791309357,\n",
       "  0.15259432792663574,\n",
       "  0.15149904787540436,\n",
       "  0.1526298224925995,\n",
       "  0.15218767523765564,\n",
       "  0.15221700072288513,\n",
       "  0.14988425374031067,\n",
       "  0.15152467787265778,\n",
       "  0.15124313533306122,\n",
       "  0.1503095179796219,\n",
       "  0.15073341131210327,\n",
       "  0.1485859453678131,\n",
       "  0.14917105436325073,\n",
       "  0.1484137624502182,\n",
       "  0.1498110443353653,\n",
       "  0.14913958311080933,\n",
       "  0.1481945514678955,\n",
       "  0.1483054757118225,\n",
       "  0.1469060331583023,\n",
       "  0.1474236398935318,\n",
       "  0.1481899619102478,\n",
       "  0.14706243574619293,\n",
       "  0.14769019186496735,\n",
       "  0.14626970887184143,\n",
       "  0.14746183156967163,\n",
       "  0.14769403636455536,\n",
       "  0.14684319496154785,\n",
       "  0.1463591456413269,\n",
       "  0.14663581550121307,\n",
       "  0.1460900902748108,\n",
       "  0.14592494070529938,\n",
       "  0.1459929198026657,\n",
       "  0.14534275233745575,\n",
       "  0.14404113590717316,\n",
       "  0.14492100477218628,\n",
       "  0.14598384499549866,\n",
       "  0.14468562602996826,\n",
       "  0.14500588178634644,\n",
       "  0.14420799911022186,\n",
       "  0.14528383314609528,\n",
       "  0.145158052444458,\n",
       "  0.14410452544689178,\n",
       "  0.1447884738445282,\n",
       "  0.1439724862575531,\n",
       "  0.14418567717075348,\n",
       "  0.14421266317367554,\n",
       "  0.144462451338768,\n",
       "  0.14416442811489105,\n",
       "  0.14380782842636108,\n",
       "  0.14450384676456451,\n",
       "  0.14377205073833466,\n",
       "  0.14469178020954132,\n",
       "  0.14443771541118622,\n",
       "  0.1429193615913391,\n",
       "  0.14268279075622559,\n",
       "  0.1430695652961731,\n",
       "  0.14351579546928406,\n",
       "  0.14466232061386108,\n",
       "  0.14272668957710266,\n",
       "  0.1422533094882965,\n",
       "  0.1434960961341858,\n",
       "  0.1433485895395279,\n",
       "  0.14383690059185028,\n",
       "  0.1428619623184204,\n",
       "  0.1435583233833313,\n",
       "  0.14405225217342377,\n",
       "  0.14217373728752136,\n",
       "  0.1428760141134262,\n",
       "  0.1432763785123825,\n",
       "  0.1436324566602707,\n",
       "  0.1427008956670761,\n",
       "  0.1425611972808838,\n",
       "  0.14266982674598694],\n",
       " 'categorical_accuracy': [0.7923176884651184,\n",
       "  0.9601779580116272,\n",
       "  0.9884982705116272,\n",
       "  0.9938151240348816,\n",
       "  0.9949001669883728,\n",
       "  0.9951171875,\n",
       "  0.99609375,\n",
       "  0.9963107705116272,\n",
       "  0.9962022304534912,\n",
       "  0.9967448115348816,\n",
       "  0.9965277910232544,\n",
       "  0.9969618320465088,\n",
       "  0.9972873330116272,\n",
       "  0.9972873330116272,\n",
       "  0.9957682490348816,\n",
       "  0.9970703125,\n",
       "  0.9968532919883728,\n",
       "  0.9976128339767456,\n",
       "  0.9970703125,\n",
       "  0.9967448115348816,\n",
       "  0.9979383945465088,\n",
       "  0.9968532919883728,\n",
       "  0.9971787929534912,\n",
       "  0.9971787929534912,\n",
       "  0.9970703125,\n",
       "  0.9978298544883728,\n",
       "  0.9969618320465088,\n",
       "  0.9976128339767456,\n",
       "  0.9978298544883728,\n",
       "  0.9981553554534912,\n",
       "  0.9981553554534912,\n",
       "  0.9976128339767456,\n",
       "  0.9984809160232544,\n",
       "  0.998046875,\n",
       "  0.9979383945465088,\n",
       "  0.9982638955116272,\n",
       "  0.9981553554534912,\n",
       "  0.9982638955116272,\n",
       "  0.9982638955116272,\n",
       "  0.9985893964767456,\n",
       "  0.9983723759651184,\n",
       "  0.9978298544883728,\n",
       "  0.9984809160232544,\n",
       "  0.9979383945465088,\n",
       "  0.9983723759651184,\n",
       "  0.998046875,\n",
       "  0.9985893964767456,\n",
       "  0.9982638955116272,\n",
       "  0.9986979365348816,\n",
       "  0.9981553554534912,\n",
       "  0.9986979365348816,\n",
       "  0.9983723759651184,\n",
       "  0.9977213740348816,\n",
       "  0.9989149570465088,\n",
       "  0.9984809160232544,\n",
       "  0.9981553554534912,\n",
       "  0.9985893964767456,\n",
       "  0.9981553554534912,\n",
       "  0.9984809160232544,\n",
       "  0.9983723759651184,\n",
       "  0.9986979365348816,\n",
       "  0.9985893964767456,\n",
       "  0.9984809160232544,\n",
       "  0.998046875,\n",
       "  0.9986979365348816,\n",
       "  0.9984809160232544,\n",
       "  0.9986979365348816,\n",
       "  0.9981553554534912,\n",
       "  0.9984809160232544,\n",
       "  0.9983723759651184,\n",
       "  0.9988064169883728,\n",
       "  0.9989149570465088,\n",
       "  0.9989149570465088,\n",
       "  0.9988064169883728,\n",
       "  0.9986979365348816,\n",
       "  0.9985893964767456,\n",
       "  0.9983723759651184,\n",
       "  0.9983723759651184,\n",
       "  0.9977213740348816,\n",
       "  0.9983723759651184,\n",
       "  0.9989149570465088,\n",
       "  0.9986979365348816,\n",
       "  0.9984809160232544,\n",
       "  0.9984809160232544,\n",
       "  0.9986979365348816,\n",
       "  0.9985893964767456,\n",
       "  0.9986979365348816,\n",
       "  0.9986979365348816,\n",
       "  0.9983723759651184,\n",
       "  0.9985893964767456,\n",
       "  0.9986979365348816,\n",
       "  0.9983723759651184,\n",
       "  0.9989149570465088,\n",
       "  0.9988064169883728,\n",
       "  0.9985893964767456,\n",
       "  0.9983723759651184,\n",
       "  0.9986979365348816,\n",
       "  0.9986979365348816,\n",
       "  0.9988064169883728,\n",
       "  0.9989149570465088]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc01b7d-a7ab-4284-964d-68598a93d134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(history.history[\\'loss\\'], label=\\' training data\\')\\nplt.plot(history.history[\\'val_loss\\'], label=\\'validation data\\')\\nplt.title(\\'Loss for Text Classification\\')\\nplt.ylabel(\\'Loss value\\')\\nplt.xlabel(\\'No. epoch\\')\\nplt.legend(loc=\"upper left\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(history.history['loss'], label=' training data')\n",
    "plt.plot(history.history['val_loss'], label='validation data')\n",
    "plt.title('Loss for Text Classification')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6006641d-83c9-425e-b84d-9451bbd391d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(history.history[\\'categorical_accuracy\\'], label=\\' (training data)\\')\\nplt.plot(history.history[\\'val_categorical_accuracy\\'], label=\\'CategoricalCrossentropy (validation data)\\')\\nplt.title(\\'CategoricalAccuracy for Text Classification\\')\\nplt.ylabel(\\'CategoricalAccuracy value\\')\\nplt.xlabel(\\'No. epoch\\')\\nplt.legend(loc=\"upper left\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(history.history['categorical_accuracy'], label=' (training data)')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='CategoricalCrossentropy (validation data)')\n",
    "plt.title('CategoricalAccuracy for Text Classification')\n",
    "plt.ylabel('CategoricalAccuracy value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d38779-c46b-4600-aaa7-752e4d5f6120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\Desc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\Desc\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc') \n",
    "json_string = Desc.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c07f08ee-072a-494b-9587-97c719629c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc\\\\Desc.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093fad61-1d01-4441-af0d-3e758dcfd3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reload model\n",
    "\n",
    "new_model = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aa4ad50-70d5-491a-86a6-c0ec45ac1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc\\\\Desc.json') as json_file:\n",
    "    json_string = json.load(json_file)\n",
    "tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0593ab06-c7f7-45ad-99d3-0bb97114bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_10172\\2438752368.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test  = np.array( tokenizer1.texts_to_sequences(test_data['Description'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test  = np.array( tokenizer1.texts_to_sequences(test_data['Description'].tolist()) )\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "285b5d0c-c6cc-4ad3-851c-d0dda819352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "[[0.98725384 0.01274614]\n",
      " [0.99856377 0.00143621]\n",
      " [0.9836872  0.01631275]\n",
      " ...\n",
      " [0.00634583 0.9936542 ]\n",
      " [0.9606546  0.03934541]\n",
      " [0.9776184  0.0223816 ]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on test  data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d03231-1179-4974-8e41-a79d81b9e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake']= predict_results\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '0'),0,test_data.pred_fake)\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '1'),1,test_data.pred_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a747c5-d56b-41b2-b46f-ddef6c577fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e92601-5e63-4df0-b3b3-6b2fdcb5902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pred_fake, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake']))\n",
    "test_data['pred_fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f32efb08-5b28-4e69-8718-4bd1d01411ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1429\n",
      "           1       0.60      0.65      0.62       184\n",
      "\n",
      "    accuracy                           0.91      1613\n",
      "   macro avg       0.78      0.80      0.79      1613\n",
      "weighted avg       0.91      0.91      0.91      1613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ed79082-76d1-4346-932c-e970cd4fee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precisionscore = precision_score(y_test, new_model.predict(x_test))\\naccuracyscore = accuracy_score(y_test, new_model.predict(x_test))\\nrecallscore = recall_score(y_test, new_model.predict(x_test))\\nf1score = f1_score(y_test, new_model.predict(x_test))\\ncm = confusion_matrix(y_test, new_model.predict(x_test))\\n\\nprint(precisionscore, accuracyscore, recallscore, f1score, cm)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"precisionscore = precision_score(y_test, new_model.predict(x_test))\n",
    "accuracyscore = accuracy_score(y_test, new_model.predict(x_test))\n",
    "recallscore = recall_score(y_test, new_model.predict(x_test))\n",
    "f1score = f1_score(y_test, new_model.predict(x_test))\n",
    "cm = confusion_matrix(y_test, new_model.predict(x_test))\n",
    "\n",
    "print(precisionscore, accuracyscore, recallscore, f1score, cm)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9202e-a347-4243-a327-1e3432c9e19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac01755-1aa1-41d5-8069-c8a0b390ea45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
