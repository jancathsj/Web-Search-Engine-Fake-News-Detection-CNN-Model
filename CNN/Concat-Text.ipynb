{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe88f91-6205-4375-ae9b-a86d5d0e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%%script C:\\Users\\Jan Catherine\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c542dc-142b-4bd7-a809-85189871a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5778bf7-46f3-494b-a66f-1b9c354f4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../Data_Collection_02/02_Preprocessing/05_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aed2f12-08dd-4251-97c2-18310735932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4409ce-fa2b-4138-8f5e-96db2d536f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('02_All_Train.csv', encoding='latin-1')\n",
    "testdata = pd.read_csv('02_All_Test.csv', encoding='latin-1')\n",
    "\n",
    "train_data = dataset\n",
    "test_data = testdata\n",
    "\n",
    "test_data.dropna(axis = 0, how ='any',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e971202-1a9c-4734-a27b-b7f93e543ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4_1 (Embedding)   (None, 90, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_4_1 (Conv1D)         (None, 88, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4_1 (  (None, 128)               0         \n",
      " GlobalMaxPooling1D)                                             \n",
      "                                                                 \n",
      " dropout_4_1 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4_1 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model1 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Title')\n",
    "new_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7640a9e3-83af-4415-9736-121cefc0e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Title\\\\Title.json') as json_file1:\n",
    "    json_string1 = json.loads(json_file1.read())\n",
    "tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(json_string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c166ed39-243a-4609-af70-86705b27ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model2 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc')\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4899e742-3ae6-4c20-901b-f463e09f18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc\\\\Desc.json') as json_file2:\n",
    "    json_string2 = json.loads(json_file2.read())\n",
    "tokenizer2 = tf.keras.preprocessing.text.tokenizer_from_json(json_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b05085-8bb9-49fd-9948-3543d17c3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_14904\\3328888694.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test1  = np.array( tokenizer1.texts_to_sequences(test_data['Title'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test1  = np.array( tokenizer1.texts_to_sequences(test_data['Title'].tolist()) )\n",
    "x_test1 = pad_sequences(x_test1, padding='post', maxlen=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a357ba14-fe95-42e6-b8db-4c1ca52b2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_14904\\4054164706.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test2  = np.array( tokenizer2.texts_to_sequences(test_data['Description'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test2  = np.array( tokenizer2.texts_to_sequences(test_data['Description'].tolist()) )\n",
    "x_test2 = pad_sequences(x_test2, padding='post', maxlen=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21c46b2-6792-4b29-b787-607fffdd8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras. models import Model\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f804b26-07d0-4674-be98-c81a2d18a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model=tf.keras.layers.Average()([new_model1.output, new_model2.output])\n",
    "\n",
    "final_model = tf.keras.models.Model(inputs=[new_model1.output, new_model2.output], outputs=merged_model)\n",
    "final_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['CategoricalAccuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e61ee3-7f10-40d5-b814-be7d7c717311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " average (Average)           (None, 2)                    0         ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fdaacfc-e0a9-4bf5-a021-2ed3c1b28137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "[[0.9986129  0.00138709]\n",
      " [0.99433863 0.00566135]\n",
      " [0.99058545 0.00941452]\n",
      " ...\n",
      " [0.00372173 0.9962783 ]\n",
      " [0.9556978  0.04430221]\n",
      " [0.9832606  0.01673941]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions1 = new_model1.predict(x_test1)\n",
    "print(predictions1)\n",
    "\n",
    "predict_results1 = predictions1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab948777-3a8f-42b8-90c6-d678401bf6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "[[0.98725384 0.01274614]\n",
      " [0.99856377 0.00143621]\n",
      " [0.9836872  0.01631275]\n",
      " ...\n",
      " [0.00634583 0.9936542 ]\n",
      " [0.9606546  0.03934541]\n",
      " [0.9776184  0.02238159]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions2 = new_model2.predict(x_test2)\n",
    "print(predictions2)\n",
    "predict_results2 = predictions2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db243396-9d14-4035-85e2-abeec4ac7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 988us/step\n",
      "[[0.9929334  0.00706661]\n",
      " [0.9964512  0.00354878]\n",
      " [0.98713636 0.01286364]\n",
      " ...\n",
      " [0.00503378 0.99496627]\n",
      " [0.9581762  0.04182381]\n",
      " [0.9804395  0.0195605 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions = final_model.predict([predictions1, predictions2])\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2777b7c2-726b-4534-9c88-2bf4c2b6829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake']= predict_results\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '0'),0,test_data.pred_fake)\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '1'),1,test_data.pred_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40891c52-fe23-48d2-b78c-3326d224b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d754639-5fd5-4baa-a698-23042e1c69be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pred_fake, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake']))\n",
    "test_data['pred_fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22cfb2e-140e-424c-9622-111a8e06227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1428\n",
      "           1       0.87      0.71      0.78       184\n",
      "\n",
      "    accuracy                           0.95      1612\n",
      "   macro avg       0.92      0.85      0.88      1612\n",
      "weighted avg       0.95      0.95      0.95      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dad2004-d7cb-4e4e-be41-acdd4948428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\All_No_URL\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\All_No_URL\\assets\n"
     ]
    }
   ],
   "source": [
    "final_model.save('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_No_URL') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13363300-8584-4579-bb2f-566aef256c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_No_URL\\\\All_No_URL.json', 'w') as outfile:\n",
    "#    json.dump(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bf070-297b-4473-be32-9331dfbf72da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
