{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b88e8e-e454-49d2-ad8e-8e63defc99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%%script C:\\Users\\Jan Catherine\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6882c84-4ec7-4025-862c-e30f906994de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57500b2d-3257-4427-9f33-9d055fc284e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../Data_Collection_02/02_Preprocessing/05_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8863d932-63b8-4c2b-a9bf-cc584f2b6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5f248c-54b6-4365-af00-0637fb458e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Activation, Flatten\\nfrom keras.layers import Convolution2D, MaxPooling2D\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd\\nimport numpy as np\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61db8ea8-a355-4d58-b625-4013889267b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31ffad0-8c40-4997-91a8-c775cb33d04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "-------Train data--------\n",
      "0    5760\n",
      "1    5760\n",
      "Name: Fake, dtype: int64\n",
      "11520\n",
      "-------------------------\n",
      "-------Test data--------\n",
      "0    1429\n",
      "1     184\n",
      "Name: Fake, dtype: int64\n",
      "1613\n",
      "-------------------------\n",
      "Train Max Length :37\n",
      "Test Max Sentence Length :37\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "dataset = pd.read_csv('01_URL_Train.csv', encoding='latin-1')\n",
    "testdata = pd.read_csv('01_URL_Test.csv', encoding='latin-1')\n",
    "\n",
    "train_data = dataset\n",
    "test_data = testdata\n",
    "\n",
    "#Oversampling\n",
    "count_class_0, count_class_1 = train_data.Fake.value_counts()\n",
    "\n",
    "df_class_0 = train_data[train_data['Fake'] == 0]\n",
    "df_class_1 = train_data[train_data['Fake'] == 1]\n",
    "\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "df_test_over = df_test_over.reset_index(drop=True)\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.Fake.value_counts())\n",
    "\n",
    "train_data = df_test_over\n",
    "\n",
    "print(train_data.Fake.value_counts())\n",
    "\n",
    "train_data.dropna(axis=0, how ='any', inplace=True)\n",
    "train_data['Num_words_url'] = train_data['URL'].apply(lambda x:len(re.findall(r\"[\\w']+\", str(x))))\n",
    "\n",
    "print('-------Train data--------')\n",
    "print(train_data['Fake'].value_counts())\n",
    "print(len(train_data))\n",
    "print('-------------------------')\n",
    "\n",
    "max_train_url_length  = train_data['Num_words_url'].max()\n",
    "\n",
    "\n",
    "\n",
    "test_data.dropna(axis = 0, how ='any',inplace=True) \n",
    "test_data['Num_words_url'] = test_data['URL'].apply(lambda x:len(re.findall(r\"[\\w']+\", str(x))))\n",
    "\n",
    "max_test_url_length  = test_data['Num_words_url'].max()\n",
    "\n",
    "print('-------Test data--------')\n",
    "print(test_data['Fake'].value_counts())\n",
    "print(len(test_data))\n",
    "print('-------------------------')\n",
    "\n",
    "print('Train Max Length :'+str(max_train_url_length))\n",
    "print('Test Max Sentence Length :'+str(max_test_url_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a2bbef-3563-46e8-a7b6-960806b53caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Num_words_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.thehindu.com/opinion/lead/a-key-ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mckinsey.com/industries/financial-...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://coronadotimes.com/news/2020/06/14/nail...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://aricjournal.biomedcentral.com/articles...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.idealista.com/en/news/property-for...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Fake  Num_words_url\n",
       "0  https://www.thehindu.com/opinion/lead/a-key-ar...     0             16\n",
       "1  https://www.mckinsey.com/industries/financial-...     0             22\n",
       "2  https://coronadotimes.com/news/2020/06/14/nail...     0             17\n",
       "3  https://aricjournal.biomedcentral.com/articles...     0             11\n",
       "4  https://www.idealista.com/en/news/property-for...     0             27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21264bed-6b54-438e-b82e-8fe0913d7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 547, 4, 44, 3384, 1, 1, 612]]\n"
     ]
    }
   ],
   "source": [
    "num_words = 12000\n",
    "\n",
    "\n",
    "URLword = Tokenizer(num_words=num_words, oov_token=\"unk\", filters='!\"#$%&()*+,./:;<=>?@[\\\\]^`{|}~\\t\\n',)\n",
    "URLword.fit_on_texts(train_data['URL'].tolist())\n",
    "\n",
    "print(str(URLword.texts_to_sequences(['https://www.thehindu.com/opinion/lead/&bill-gates012/100??0'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acc75e4e-3464-4f1b-ab15-d89651108d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 547, 4, 44, 3384, 1, 6, 1455]]\n"
     ]
    }
   ],
   "source": [
    "print(str(URLword.texts_to_sequences(['https://www.thehindu.com/opinion/lead/gates/news/covid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fbc624-d2a4-41b1-be0a-e7683b4d2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:9216\n",
      "Class distributionCounter({0: 4608, 1: 4608})\n",
      "Valid data len:2304\n",
      "Class distributionCounter({1: 1152, 0: 1152})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_9208\\3143876583.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array( URLword.texts_to_sequences(X_train) )\n",
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_9208\\3143876583.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_valid = np.array( URLword.texts_to_sequences(X_valid) )\n",
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_9208\\3143876583.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test  = np.array( URLword.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2    3 1312    4    6  147 7678    8    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data['URL'].tolist(),\\\n",
    "                                                      train_data['Fake'].tolist(),\\\n",
    "                                                      test_size=0.2,\\\n",
    "                                                      stratify = train_data['Fake'].tolist(),\\\n",
    "                                                      random_state=0)\n",
    "\n",
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution'+str(Counter(y_train)))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution'+ str(Counter(y_valid)))\n",
    "\n",
    "x_train = np.array( URLword.texts_to_sequences(X_train) )\n",
    "x_valid = np.array( URLword.texts_to_sequences(X_valid) )\n",
    "x_test  = np.array( URLword.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=40)\n",
    "x_valid = pad_sequences(x_valid, padding='post', maxlen=40)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=40)\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_labels = le.fit_transform(y_train)\n",
    "train_labels = np.asarray( tf.keras.utils.to_categorical(train_labels, 2))\n",
    "#print(train_labels)\n",
    "valid_labels = le.transform(y_valid)\n",
    "valid_labels = np.asarray( tf.keras.utils.to_categorical(valid_labels, 2))\n",
    "\n",
    "\n",
    "test_labels = le.transform(test_data['Fake'].tolist())\n",
    "test_labels = np.asarray(tf.keras.utils.to_categorical(test_labels, 2))\n",
    "list(le.classes_)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,train_labels))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0143d15f-85f2-4690-8a64-e438f3f4656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Num_words_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://bhekisisa.org/article/2020-06-03-coron...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.express.co.uk/travel/articles/1246...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.thesun.co.uk/tvandshowbiz/11851914...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.inquirer.com/opinion/china-reparat...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://scdhec.gov/covid19/covid-19-testing-lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Fake  Num_words_url\n",
       "0  https://bhekisisa.org/article/2020-06-03-coron...     0             25\n",
       "1  https://www.express.co.uk/travel/articles/1246...     0             23\n",
       "2  https://www.thesun.co.uk/tvandshowbiz/11851914...     0             12\n",
       "3  https://www.inquirer.com/opinion/china-reparat...     0             15\n",
       "4  https://scdhec.gov/covid19/covid-19-testing-lo...     0              8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bf38b8-3b43-49a7-a1b8-90da4888318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Train dataset ====\n",
      "tf.Tensor(\n",
      "[   2    3 1312    4    6  147 7678    8    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   2 3927    4   22    5   14 3928    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   2    3 7563    9 1472 2773 7564    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "======Validation dataset ====\n",
      "tf.Tensor(\n",
      "[  2   3 521   4 522 523   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0], shape=(40,), dtype=int32) tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   2    3 1283    9  870  126  186   43 1284  537 1285   43 1088   18\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   2    3   59    4    5   13   57   15   68 5086    8    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "======Test dataset ====\n",
      "tf.Tensor(\n",
      "[   2 8441    9    7 8442    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 2  3 32 11 10 38 16  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   2    3   74   11   10 3176 6509 6510    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(40,), dtype=int32) tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "print('======Train dataset ====')\n",
    "for value,label in train_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break\n",
    "count =0\n",
    "print('======Validation dataset ====')\n",
    "for value,label in valid_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break\n",
    "count = 0\n",
    "print('======Test dataset ====')\n",
    "for value,label in test_ds:\n",
    "    count += 1\n",
    "    print(value,label)\n",
    "    if count==3:\n",
    "        break  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dc6838-cfe5-4647-8591-125720406e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 64)            750016    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 7s 21ms/step - loss: 0.5264 - categorical_accuracy: 0.8138\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2022 - categorical_accuracy: 0.9754\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1466 - categorical_accuracy: 0.9921\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1306 - categorical_accuracy: 0.9966\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1251 - categorical_accuracy: 0.9972\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1229 - categorical_accuracy: 0.9977\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1233 - categorical_accuracy: 0.9976\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1212 - categorical_accuracy: 0.9976\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1204 - categorical_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1199 - categorical_accuracy: 0.9976\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1192 - categorical_accuracy: 0.9980\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1202 - categorical_accuracy: 0.9976\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1191 - categorical_accuracy: 0.9980\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1208 - categorical_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1188 - categorical_accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1186 - categorical_accuracy: 0.9982\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1180 - categorical_accuracy: 0.9980\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1195 - categorical_accuracy: 0.9983\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1193 - categorical_accuracy: 0.9978\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1188 - categorical_accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1183 - categorical_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 6s 23ms/step - loss: 0.1173 - categorical_accuracy: 0.9982\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1179 - categorical_accuracy: 0.9978\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1169 - categorical_accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1179 - categorical_accuracy: 0.9975\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1173 - categorical_accuracy: 0.9975\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1177 - categorical_accuracy: 0.9978\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1168 - categorical_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1171 - categorical_accuracy: 0.9975\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1161 - categorical_accuracy: 0.9982\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1170 - categorical_accuracy: 0.9975\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1179 - categorical_accuracy: 0.9976\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1166 - categorical_accuracy: 0.9978\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1167 - categorical_accuracy: 0.9975\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1163 - categorical_accuracy: 0.9983\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1168 - categorical_accuracy: 0.9975\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1156 - categorical_accuracy: 0.9978\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1158 - categorical_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1162 - categorical_accuracy: 0.9982\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1157 - categorical_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1158 - categorical_accuracy: 0.9983\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1162 - categorical_accuracy: 0.9979\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1144 - categorical_accuracy: 0.9985\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1153 - categorical_accuracy: 0.9982\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1152 - categorical_accuracy: 0.9979\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1148 - categorical_accuracy: 0.9985\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1143 - categorical_accuracy: 0.9983\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1146 - categorical_accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1152 - categorical_accuracy: 0.9978\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1139 - categorical_accuracy: 0.9980\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1146 - categorical_accuracy: 0.9979\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1153 - categorical_accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1142 - categorical_accuracy: 0.9982\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1138 - categorical_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1144 - categorical_accuracy: 0.9984\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1136 - categorical_accuracy: 0.9983\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1146 - categorical_accuracy: 0.9978\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1153 - categorical_accuracy: 0.9979\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1144 - categorical_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1139 - categorical_accuracy: 0.9982\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1143 - categorical_accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1136 - categorical_accuracy: 0.9985\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1141 - categorical_accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1140 - categorical_accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1130 - categorical_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1137 - categorical_accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1133 - categorical_accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1127 - categorical_accuracy: 0.9983\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1130 - categorical_accuracy: 0.9983\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1141 - categorical_accuracy: 0.9980\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1139 - categorical_accuracy: 0.9982\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1131 - categorical_accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1127 - categorical_accuracy: 0.9983\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1138 - categorical_accuracy: 0.9983\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1132 - categorical_accuracy: 0.9980\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1136 - categorical_accuracy: 0.9982\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1135 - categorical_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1136 - categorical_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1135 - categorical_accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1124 - categorical_accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1129 - categorical_accuracy: 0.9980\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1133 - categorical_accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1114 - categorical_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1137 - categorical_accuracy: 0.9978\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1124 - categorical_accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1131 - categorical_accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1130 - categorical_accuracy: 0.9985\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1134 - categorical_accuracy: 0.9978\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1115 - categorical_accuracy: 0.9985\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1133 - categorical_accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1128 - categorical_accuracy: 0.9980\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1120 - categorical_accuracy: 0.9983\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1129 - categorical_accuracy: 0.9982\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1128 - categorical_accuracy: 0.9983\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 11s 36ms/step - loss: 0.1129 - categorical_accuracy: 0.9979\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1129 - categorical_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1121 - categorical_accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1116 - categorical_accuracy: 0.9984\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1125 - categorical_accuracy: 0.9980\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1127 - categorical_accuracy: 0.9980\n",
      "Score for fold 1: loss of 0.1345098316669464; categorical_accuracy of 99.30555820465088%\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 40, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 10s 29ms/step - loss: 0.5320 - categorical_accuracy: 0.8028\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1943 - categorical_accuracy: 0.9791\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1405 - categorical_accuracy: 0.9950\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1276 - categorical_accuracy: 0.9969\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1236 - categorical_accuracy: 0.9975\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1230 - categorical_accuracy: 0.9967\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1208 - categorical_accuracy: 0.9975\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1205 - categorical_accuracy: 0.9973\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1186 - categorical_accuracy: 0.9974\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1193 - categorical_accuracy: 0.9975\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1190 - categorical_accuracy: 0.9978\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1183 - categorical_accuracy: 0.9978\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1177 - categorical_accuracy: 0.9978\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1182 - categorical_accuracy: 0.9974\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1186 - categorical_accuracy: 0.9974\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1176 - categorical_accuracy: 0.9978\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1179 - categorical_accuracy: 0.9976\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1167 - categorical_accuracy: 0.9983\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1163 - categorical_accuracy: 0.9979\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1186 - categorical_accuracy: 0.9973\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 16s 54ms/step - loss: 0.1170 - categorical_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1174 - categorical_accuracy: 0.9973\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1165 - categorical_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1171 - categorical_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1173 - categorical_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1172 - categorical_accuracy: 0.9976\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1163 - categorical_accuracy: 0.9975\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1172 - categorical_accuracy: 0.9970\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1170 - categorical_accuracy: 0.9978\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1165 - categorical_accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1156 - categorical_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1155 - categorical_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1162 - categorical_accuracy: 0.9978\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1166 - categorical_accuracy: 0.9974\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1152 - categorical_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1152 - categorical_accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1158 - categorical_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1152 - categorical_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1146 - categorical_accuracy: 0.9979\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1147 - categorical_accuracy: 0.9979\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1148 - categorical_accuracy: 0.9980\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1141 - categorical_accuracy: 0.9983\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1138 - categorical_accuracy: 0.9982\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1142 - categorical_accuracy: 0.9983\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1144 - categorical_accuracy: 0.9976\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1137 - categorical_accuracy: 0.9982\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1136 - categorical_accuracy: 0.9982\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1135 - categorical_accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1141 - categorical_accuracy: 0.9980\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1136 - categorical_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1135 - categorical_accuracy: 0.9978\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1133 - categorical_accuracy: 0.9982\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1132 - categorical_accuracy: 0.9980\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1131 - categorical_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1133 - categorical_accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1128 - categorical_accuracy: 0.9982\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1119 - categorical_accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1110 - categorical_accuracy: 0.9985\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1120 - categorical_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1122 - categorical_accuracy: 0.9980\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1124 - categorical_accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1120 - categorical_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1121 - categorical_accuracy: 0.9978\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1121 - categorical_accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1131 - categorical_accuracy: 0.9974\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1117 - categorical_accuracy: 0.9982\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1117 - categorical_accuracy: 0.9983\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1111 - categorical_accuracy: 0.9979\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1108 - categorical_accuracy: 0.9985\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1121 - categorical_accuracy: 0.9983\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1115 - categorical_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1116 - categorical_accuracy: 0.9978\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1121 - categorical_accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1114 - categorical_accuracy: 0.9983\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1113 - categorical_accuracy: 0.9985\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1110 - categorical_accuracy: 0.9980\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1114 - categorical_accuracy: 0.9980\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1106 - categorical_accuracy: 0.9983\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1112 - categorical_accuracy: 0.9980\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 12s 42ms/step - loss: 0.1113 - categorical_accuracy: 0.9980\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1106 - categorical_accuracy: 0.9983\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1116 - categorical_accuracy: 0.9983\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1109 - categorical_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1099 - categorical_accuracy: 0.9985\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1101 - categorical_accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1105 - categorical_accuracy: 0.9980\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1111 - categorical_accuracy: 0.9979\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1106 - categorical_accuracy: 0.9979\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1109 - categorical_accuracy: 0.9978\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1108 - categorical_accuracy: 0.9982\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1110 - categorical_accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1103 - categorical_accuracy: 0.9978\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1095 - categorical_accuracy: 0.9987\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1110 - categorical_accuracy: 0.9983\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1106 - categorical_accuracy: 0.9978\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1098 - categorical_accuracy: 0.9984\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1103 - categorical_accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1103 - categorical_accuracy: 0.9979\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1103 - categorical_accuracy: 0.9978\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.1104 - categorical_accuracy: 0.9984\n",
      "Score for fold 2: loss of 0.12136513739824295; categorical_accuracy of 99.47916865348816%\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 40, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 13s 29ms/step - loss: 0.5380 - categorical_accuracy: 0.8043\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.2123 - categorical_accuracy: 0.9711\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1528 - categorical_accuracy: 0.9920\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1363 - categorical_accuracy: 0.9964\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1293 - categorical_accuracy: 0.9976\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1266 - categorical_accuracy: 0.9978\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1245 - categorical_accuracy: 0.9985\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1254 - categorical_accuracy: 0.9987\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1245 - categorical_accuracy: 0.9980\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1234 - categorical_accuracy: 0.9990\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 13s 47ms/step - loss: 0.1237 - categorical_accuracy: 0.9991\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 18s 61ms/step - loss: 0.1237 - categorical_accuracy: 0.9986\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 17s 59ms/step - loss: 0.1236 - categorical_accuracy: 0.9984\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 14s 48ms/step - loss: 0.1226 - categorical_accuracy: 0.9990\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 11s 39ms/step - loss: 0.1242 - categorical_accuracy: 0.9984\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1233 - categorical_accuracy: 0.9985\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1234 - categorical_accuracy: 0.9985\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1226 - categorical_accuracy: 0.9990\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1237 - categorical_accuracy: 0.9985\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1234 - categorical_accuracy: 0.9979\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1222 - categorical_accuracy: 0.9987\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1216 - categorical_accuracy: 0.9987\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1220 - categorical_accuracy: 0.9987\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1221 - categorical_accuracy: 0.9991\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1210 - categorical_accuracy: 0.9991\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1223 - categorical_accuracy: 0.9985\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1216 - categorical_accuracy: 0.9985\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1215 - categorical_accuracy: 0.9991\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1208 - categorical_accuracy: 0.9986\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1213 - categorical_accuracy: 0.9989\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1219 - categorical_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1213 - categorical_accuracy: 0.9987\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1203 - categorical_accuracy: 0.9992\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1205 - categorical_accuracy: 0.9987\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1206 - categorical_accuracy: 0.9987\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1205 - categorical_accuracy: 0.9986\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.1204 - categorical_accuracy: 0.9991\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1197 - categorical_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1201 - categorical_accuracy: 0.9986\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1201 - categorical_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 13s 43ms/step - loss: 0.1195 - categorical_accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1191 - categorical_accuracy: 0.9990\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 11s 37ms/step - loss: 0.1189 - categorical_accuracy: 0.9990\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1198 - categorical_accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1202 - categorical_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1196 - categorical_accuracy: 0.9992\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1196 - categorical_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1186 - categorical_accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1191 - categorical_accuracy: 0.9988\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1188 - categorical_accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1197 - categorical_accuracy: 0.9990\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1186 - categorical_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1184 - categorical_accuracy: 0.9988\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1194 - categorical_accuracy: 0.9987\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1191 - categorical_accuracy: 0.9984\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1190 - categorical_accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1173 - categorical_accuracy: 0.9993\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1178 - categorical_accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1193 - categorical_accuracy: 0.9980\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1180 - categorical_accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1172 - categorical_accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1179 - categorical_accuracy: 0.9987\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1175 - categorical_accuracy: 0.9990\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1172 - categorical_accuracy: 0.9991\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1173 - categorical_accuracy: 0.9990\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 13s 46ms/step - loss: 0.1173 - categorical_accuracy: 0.9990\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1178 - categorical_accuracy: 0.9988\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1177 - categorical_accuracy: 0.9988\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1174 - categorical_accuracy: 0.9990\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1180 - categorical_accuracy: 0.9985\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1175 - categorical_accuracy: 0.9990\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1166 - categorical_accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1163 - categorical_accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1163 - categorical_accuracy: 0.9993\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1167 - categorical_accuracy: 0.9989\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1176 - categorical_accuracy: 0.9985\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1163 - categorical_accuracy: 0.9990\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1161 - categorical_accuracy: 0.9988\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1170 - categorical_accuracy: 0.9990\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1166 - categorical_accuracy: 0.9995\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1160 - categorical_accuracy: 0.9990\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1164 - categorical_accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1171 - categorical_accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1165 - categorical_accuracy: 0.9992\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1170 - categorical_accuracy: 0.9988\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1176 - categorical_accuracy: 0.9985\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1171 - categorical_accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1171 - categorical_accuracy: 0.9988\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1163 - categorical_accuracy: 0.9991\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1159 - categorical_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1164 - categorical_accuracy: 0.9991\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1156 - categorical_accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1152 - categorical_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1166 - categorical_accuracy: 0.9991\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1157 - categorical_accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1158 - categorical_accuracy: 0.9993\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 6s 23ms/step - loss: 0.1159 - categorical_accuracy: 0.9990\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1160 - categorical_accuracy: 0.9993\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1161 - categorical_accuracy: 0.9988\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1157 - categorical_accuracy: 0.9991\n",
      "Score for fold 3: loss of 0.137055903673172; categorical_accuracy of 99.13194179534912%\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 40, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 10s 28ms/step - loss: 0.5282 - categorical_accuracy: 0.8111\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1989 - categorical_accuracy: 0.9767\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1455 - categorical_accuracy: 0.9935\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1289 - categorical_accuracy: 0.9973\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 11s 40ms/step - loss: 0.1239 - categorical_accuracy: 0.9974\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1213 - categorical_accuracy: 0.9977\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1200 - categorical_accuracy: 0.9978\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1197 - categorical_accuracy: 0.9977\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1188 - categorical_accuracy: 0.9982\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1187 - categorical_accuracy: 0.9976\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1190 - categorical_accuracy: 0.9979\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1181 - categorical_accuracy: 0.9978\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1181 - categorical_accuracy: 0.9979\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1180 - categorical_accuracy: 0.9977\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1174 - categorical_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1184 - categorical_accuracy: 0.9974\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1173 - categorical_accuracy: 0.9976\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1174 - categorical_accuracy: 0.9973\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1178 - categorical_accuracy: 0.9978\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1188 - categorical_accuracy: 0.9966\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1157 - categorical_accuracy: 0.9986\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1176 - categorical_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1178 - categorical_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1167 - categorical_accuracy: 0.9974\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1177 - categorical_accuracy: 0.9978\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1182 - categorical_accuracy: 0.9974\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.1158 - categorical_accuracy: 0.9982\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1162 - categorical_accuracy: 0.9978\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1172 - categorical_accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1178 - categorical_accuracy: 0.9971\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1161 - categorical_accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1164 - categorical_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 10s 35ms/step - loss: 0.1161 - categorical_accuracy: 0.9976\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1166 - categorical_accuracy: 0.9978\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1159 - categorical_accuracy: 0.9977\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1164 - categorical_accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1156 - categorical_accuracy: 0.9979\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1167 - categorical_accuracy: 0.9975\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1154 - categorical_accuracy: 0.9978\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1161 - categorical_accuracy: 0.9972\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1158 - categorical_accuracy: 0.9975\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1167 - categorical_accuracy: 0.9978\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1157 - categorical_accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1157 - categorical_accuracy: 0.9975\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1151 - categorical_accuracy: 0.9982\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1156 - categorical_accuracy: 0.9975\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1150 - categorical_accuracy: 0.9979\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1153 - categorical_accuracy: 0.9977\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1146 - categorical_accuracy: 0.9983\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1149 - categorical_accuracy: 0.9978\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1141 - categorical_accuracy: 0.9980\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1151 - categorical_accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1145 - categorical_accuracy: 0.9977\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1141 - categorical_accuracy: 0.9982\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1151 - categorical_accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1143 - categorical_accuracy: 0.9977\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1150 - categorical_accuracy: 0.9979\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1141 - categorical_accuracy: 0.9978\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1146 - categorical_accuracy: 0.9982\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 13s 45ms/step - loss: 0.1146 - categorical_accuracy: 0.9978\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1150 - categorical_accuracy: 0.9975\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1139 - categorical_accuracy: 0.9982\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1138 - categorical_accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1150 - categorical_accuracy: 0.9975\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1141 - categorical_accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1144 - categorical_accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1145 - categorical_accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1146 - categorical_accuracy: 0.9978\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1138 - categorical_accuracy: 0.9979\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1140 - categorical_accuracy: 0.9979\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1129 - categorical_accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1146 - categorical_accuracy: 0.9978\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1147 - categorical_accuracy: 0.9977\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1137 - categorical_accuracy: 0.9978\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1134 - categorical_accuracy: 0.9977\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1122 - categorical_accuracy: 0.9985\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1139 - categorical_accuracy: 0.9978\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1141 - categorical_accuracy: 0.9979\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1141 - categorical_accuracy: 0.9976\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1119 - categorical_accuracy: 0.9985\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1129 - categorical_accuracy: 0.9979\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1131 - categorical_accuracy: 0.9978\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 8s 30ms/step - loss: 0.1145 - categorical_accuracy: 0.9977\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1129 - categorical_accuracy: 0.9979\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1125 - categorical_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1128 - categorical_accuracy: 0.9979\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1131 - categorical_accuracy: 0.9977\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1126 - categorical_accuracy: 0.9980\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1121 - categorical_accuracy: 0.9984\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1134 - categorical_accuracy: 0.9977\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1129 - categorical_accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1122 - categorical_accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1130 - categorical_accuracy: 0.9980\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1112 - categorical_accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1126 - categorical_accuracy: 0.9977\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1120 - categorical_accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1113 - categorical_accuracy: 0.9980\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1134 - categorical_accuracy: 0.9978\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1126 - categorical_accuracy: 0.9979\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1130 - categorical_accuracy: 0.9978\n",
      "Score for fold 4: loss of 0.12402170151472092; categorical_accuracy of 99.39236044883728%\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 40, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 12s 34ms/step - loss: 0.5314 - categorical_accuracy: 0.8137\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1998 - categorical_accuracy: 0.9771\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1410 - categorical_accuracy: 0.9956\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1293 - categorical_accuracy: 0.9971\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1253 - categorical_accuracy: 0.9974\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1223 - categorical_accuracy: 0.9978\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1228 - categorical_accuracy: 0.9973\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1210 - categorical_accuracy: 0.9978\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1222 - categorical_accuracy: 0.9974\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1198 - categorical_accuracy: 0.9982\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1203 - categorical_accuracy: 0.9976\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1215 - categorical_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1195 - categorical_accuracy: 0.9982\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1196 - categorical_accuracy: 0.9976\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1212 - categorical_accuracy: 0.9970\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1201 - categorical_accuracy: 0.9977\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1201 - categorical_accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1197 - categorical_accuracy: 0.9976\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1203 - categorical_accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1202 - categorical_accuracy: 0.9971\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1193 - categorical_accuracy: 0.9976\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1205 - categorical_accuracy: 0.9966\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1190 - categorical_accuracy: 0.9976\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1202 - categorical_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1190 - categorical_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1201 - categorical_accuracy: 0.9975\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1204 - categorical_accuracy: 0.9970\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1191 - categorical_accuracy: 0.9967\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1195 - categorical_accuracy: 0.9980\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1192 - categorical_accuracy: 0.9975\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 8s 26ms/step - loss: 0.1193 - categorical_accuracy: 0.9974\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1180 - categorical_accuracy: 0.9983\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1179 - categorical_accuracy: 0.9976\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1188 - categorical_accuracy: 0.9972\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 11s 38ms/step - loss: 0.1183 - categorical_accuracy: 0.9975\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1177 - categorical_accuracy: 0.9978\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 12s 40ms/step - loss: 0.1194 - categorical_accuracy: 0.9963\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.1172 - categorical_accuracy: 0.9980\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1189 - categorical_accuracy: 0.9974\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1183 - categorical_accuracy: 0.9969\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1182 - categorical_accuracy: 0.9975\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1174 - categorical_accuracy: 0.9976\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1184 - categorical_accuracy: 0.9967\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1164 - categorical_accuracy: 0.9982\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1162 - categorical_accuracy: 0.9973\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1161 - categorical_accuracy: 0.9976\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1182 - categorical_accuracy: 0.9972\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1148 - categorical_accuracy: 0.9978\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1173 - categorical_accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1160 - categorical_accuracy: 0.9976\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.1170 - categorical_accuracy: 0.9971\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1169 - categorical_accuracy: 0.9972\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1158 - categorical_accuracy: 0.9982\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1157 - categorical_accuracy: 0.9979\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1160 - categorical_accuracy: 0.9970\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1159 - categorical_accuracy: 0.9973\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 13s 44ms/step - loss: 0.1159 - categorical_accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 9s 33ms/step - loss: 0.1158 - categorical_accuracy: 0.9975\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1154 - categorical_accuracy: 0.9974\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1167 - categorical_accuracy: 0.9972\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1156 - categorical_accuracy: 0.9978\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1160 - categorical_accuracy: 0.9973\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1147 - categorical_accuracy: 0.9973\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 10s 34ms/step - loss: 0.1153 - categorical_accuracy: 0.9973\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1155 - categorical_accuracy: 0.9977\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1155 - categorical_accuracy: 0.9974\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1156 - categorical_accuracy: 0.9975\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1145 - categorical_accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1155 - categorical_accuracy: 0.9974\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1152 - categorical_accuracy: 0.9973\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1154 - categorical_accuracy: 0.9977\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1151 - categorical_accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1152 - categorical_accuracy: 0.9978\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 14s 49ms/step - loss: 0.1151 - categorical_accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 10s 36ms/step - loss: 0.1146 - categorical_accuracy: 0.9979\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1151 - categorical_accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1146 - categorical_accuracy: 0.9982\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 7s 26ms/step - loss: 0.1143 - categorical_accuracy: 0.9980\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1149 - categorical_accuracy: 0.9970\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 10s 33ms/step - loss: 0.1150 - categorical_accuracy: 0.9973\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 14s 47ms/step - loss: 0.1146 - categorical_accuracy: 0.9976\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 14s 50ms/step - loss: 0.1148 - categorical_accuracy: 0.9977\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1139 - categorical_accuracy: 0.9978\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1145 - categorical_accuracy: 0.9977\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1148 - categorical_accuracy: 0.9977\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1149 - categorical_accuracy: 0.9975\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1142 - categorical_accuracy: 0.9977\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.1148 - categorical_accuracy: 0.9972\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1150 - categorical_accuracy: 0.9975\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1137 - categorical_accuracy: 0.9982\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1139 - categorical_accuracy: 0.9974\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.1143 - categorical_accuracy: 0.9976\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.1142 - categorical_accuracy: 0.9977\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1147 - categorical_accuracy: 0.9974\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1147 - categorical_accuracy: 0.9976\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1138 - categorical_accuracy: 0.9977\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 9s 30ms/step - loss: 0.1126 - categorical_accuracy: 0.9982\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1141 - categorical_accuracy: 0.9977\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 9s 31ms/step - loss: 0.1131 - categorical_accuracy: 0.9977\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 9s 32ms/step - loss: 0.1132 - categorical_accuracy: 0.9979\n",
      "Score for fold 5: loss of 0.1365675926208496; categorical_accuracy of 99.21875%\n"
     ]
    }
   ],
   "source": [
    "#CNN MODEL\n",
    "\n",
    "max_features = 11718\n",
    "embedding_dim = 64 #same as URLNet\n",
    "sequence_length = 40\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "inputs = np.concatenate((x_train,x_valid), axis=0)\n",
    "targets = np.concatenate((train_labels, valid_labels), axis=0)\n",
    "\n",
    "#regularizer prevents overfitting\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(max_features +1, embedding_dim, input_length=sequence_length,\\\n",
    "                                        embeddings_regularizer = regularizers.l2(0.0005)))                                    \n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(128,3, activation='relu',\\\n",
    "                                     kernel_regularizer = regularizers.l2(0.0005),\\\n",
    "                                     bias_regularizer = regularizers.l2(0.0005)))                               \n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.5)) #to reduce overfitting\n",
    "\n",
    "    #final classification, 2 classes\n",
    "    model.add(tf.keras.layers.Dense(2, activation='sigmoid',\\\n",
    "                                    kernel_regularizer=regularizers.l2(0.001),\\\n",
    "                                    bias_regularizer=regularizers.l2(0.001),))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer='Nadam', metrics=[\"CategoricalAccuracy\"])\n",
    "    \n",
    "    epochs = 100\n",
    "    # Fit the model using the train and test datasets.\n",
    "    #history = model.fit(x_train, train_labels,validation_data= (x_test,test_labels),epochs=epochs )\n",
    "    history = model.fit(inputs[train], targets[train],\n",
    "                        epochs= epochs ,\n",
    "                        verbose=1)\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4aa2aa-6502-4e52-bffb-e5d32167ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.1345098316669464 - Accuracy: 99.30555820465088%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.12136513739824295 - Accuracy: 99.47916865348816%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.137055903673172 - Accuracy: 99.13194179534912%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.12402170151472092 - Accuracy: 99.39236044883728%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.1365675926208496 - Accuracy: 99.21875%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 99.30555582046509 (+- 0.12276281154030338)\n",
      "> Loss: 0.13070403337478637\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b715be-0b02-486a-b13c-e63f567aa4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5313675403594971,\n",
       "  0.19979873299598694,\n",
       "  0.14098471403121948,\n",
       "  0.12931157648563385,\n",
       "  0.12532496452331543,\n",
       "  0.12225338071584702,\n",
       "  0.12276589870452881,\n",
       "  0.12097842246294022,\n",
       "  0.12222182750701904,\n",
       "  0.11975150555372238,\n",
       "  0.12034854292869568,\n",
       "  0.12149621546268463,\n",
       "  0.1195167824625969,\n",
       "  0.11958762258291245,\n",
       "  0.12122979760169983,\n",
       "  0.12014549225568771,\n",
       "  0.12011817842721939,\n",
       "  0.11969167739152908,\n",
       "  0.12030240148305893,\n",
       "  0.12020524591207504,\n",
       "  0.11931528151035309,\n",
       "  0.1205085813999176,\n",
       "  0.11900349706411362,\n",
       "  0.12023723125457764,\n",
       "  0.1190003827214241,\n",
       "  0.12011093646287918,\n",
       "  0.12037459760904312,\n",
       "  0.1191348135471344,\n",
       "  0.11945191770792007,\n",
       "  0.11917661130428314,\n",
       "  0.11931359767913818,\n",
       "  0.11799805611371994,\n",
       "  0.11785277724266052,\n",
       "  0.11876413226127625,\n",
       "  0.11834987252950668,\n",
       "  0.11773988604545593,\n",
       "  0.11944953352212906,\n",
       "  0.11718656122684479,\n",
       "  0.11892770230770111,\n",
       "  0.11828948557376862,\n",
       "  0.11819843202829361,\n",
       "  0.11743625998497009,\n",
       "  0.11842034757137299,\n",
       "  0.11637014895677567,\n",
       "  0.11619430035352707,\n",
       "  0.11606999486684799,\n",
       "  0.11823225021362305,\n",
       "  0.11483851075172424,\n",
       "  0.11728063970804214,\n",
       "  0.11595216393470764,\n",
       "  0.11700129508972168,\n",
       "  0.1169072687625885,\n",
       "  0.11581749469041824,\n",
       "  0.11568678915500641,\n",
       "  0.11604750156402588,\n",
       "  0.11586686968803406,\n",
       "  0.115938201546669,\n",
       "  0.11581403762102127,\n",
       "  0.11539276689291,\n",
       "  0.11665194481611252,\n",
       "  0.1155969426035881,\n",
       "  0.11600923538208008,\n",
       "  0.11467838287353516,\n",
       "  0.11527415364980698,\n",
       "  0.11553505808115005,\n",
       "  0.1154552549123764,\n",
       "  0.11562427133321762,\n",
       "  0.11449726670980453,\n",
       "  0.11552228033542633,\n",
       "  0.11517100781202316,\n",
       "  0.11540762335062027,\n",
       "  0.11505112051963806,\n",
       "  0.11520057171583176,\n",
       "  0.11514636129140854,\n",
       "  0.1146484762430191,\n",
       "  0.11510348320007324,\n",
       "  0.11460015177726746,\n",
       "  0.11430840939283371,\n",
       "  0.11493226140737534,\n",
       "  0.11496894806623459,\n",
       "  0.11455173045396805,\n",
       "  0.11475062370300293,\n",
       "  0.11390052735805511,\n",
       "  0.11451397836208344,\n",
       "  0.1148362010717392,\n",
       "  0.11487597972154617,\n",
       "  0.11422967910766602,\n",
       "  0.11481384187936783,\n",
       "  0.11504324525594711,\n",
       "  0.11372657865285873,\n",
       "  0.11394425481557846,\n",
       "  0.11431431770324707,\n",
       "  0.11421452462673187,\n",
       "  0.11472569406032562,\n",
       "  0.11466120183467865,\n",
       "  0.1138007789850235,\n",
       "  0.1126013994216919,\n",
       "  0.11412763595581055,\n",
       "  0.11309418082237244,\n",
       "  0.1131749153137207],\n",
       " 'categorical_accuracy': [0.8136935830116272,\n",
       "  0.9771050214767456,\n",
       "  0.9955512285232544,\n",
       "  0.9970703125,\n",
       "  0.9973958134651184,\n",
       "  0.9978298544883728,\n",
       "  0.9972873330116272,\n",
       "  0.9978298544883728,\n",
       "  0.9973958134651184,\n",
       "  0.9981553554534912,\n",
       "  0.9976128339767456,\n",
       "  0.9977213740348816,\n",
       "  0.9981553554534912,\n",
       "  0.9976128339767456,\n",
       "  0.9969618320465088,\n",
       "  0.9977213740348816,\n",
       "  0.9975043535232544,\n",
       "  0.9976128339767456,\n",
       "  0.9976128339767456,\n",
       "  0.9970703125,\n",
       "  0.9976128339767456,\n",
       "  0.9966362714767456,\n",
       "  0.9976128339767456,\n",
       "  0.9976128339767456,\n",
       "  0.9976128339767456,\n",
       "  0.9975043535232544,\n",
       "  0.9969618320465088,\n",
       "  0.9967448115348816,\n",
       "  0.998046875,\n",
       "  0.9975043535232544,\n",
       "  0.9973958134651184,\n",
       "  0.9982638955116272,\n",
       "  0.9976128339767456,\n",
       "  0.9971787929534912,\n",
       "  0.9975043535232544,\n",
       "  0.9978298544883728,\n",
       "  0.9963107705116272,\n",
       "  0.998046875,\n",
       "  0.9973958134651184,\n",
       "  0.9968532919883728,\n",
       "  0.9975043535232544,\n",
       "  0.9976128339767456,\n",
       "  0.9967448115348816,\n",
       "  0.9981553554534912,\n",
       "  0.9972873330116272,\n",
       "  0.9976128339767456,\n",
       "  0.9971787929534912,\n",
       "  0.9978298544883728,\n",
       "  0.9971787929534912,\n",
       "  0.9976128339767456,\n",
       "  0.9970703125,\n",
       "  0.9971787929534912,\n",
       "  0.9981553554534912,\n",
       "  0.9979383945465088,\n",
       "  0.9969618320465088,\n",
       "  0.9972873330116272,\n",
       "  0.9972873330116272,\n",
       "  0.9975043535232544,\n",
       "  0.9973958134651184,\n",
       "  0.9971787929534912,\n",
       "  0.9978298544883728,\n",
       "  0.9972873330116272,\n",
       "  0.9972873330116272,\n",
       "  0.9972873330116272,\n",
       "  0.9977213740348816,\n",
       "  0.9973958134651184,\n",
       "  0.9975043535232544,\n",
       "  0.9977213740348816,\n",
       "  0.9973958134651184,\n",
       "  0.9972873330116272,\n",
       "  0.9977213740348816,\n",
       "  0.9977213740348816,\n",
       "  0.9978298544883728,\n",
       "  0.9977213740348816,\n",
       "  0.9979383945465088,\n",
       "  0.9973958134651184,\n",
       "  0.9981553554534912,\n",
       "  0.998046875,\n",
       "  0.9969618320465088,\n",
       "  0.9972873330116272,\n",
       "  0.9976128339767456,\n",
       "  0.9977213740348816,\n",
       "  0.9978298544883728,\n",
       "  0.9977213740348816,\n",
       "  0.9977213740348816,\n",
       "  0.9975043535232544,\n",
       "  0.9977213740348816,\n",
       "  0.9971787929534912,\n",
       "  0.9975043535232544,\n",
       "  0.9981553554534912,\n",
       "  0.9973958134651184,\n",
       "  0.9976128339767456,\n",
       "  0.9977213740348816,\n",
       "  0.9973958134651184,\n",
       "  0.9976128339767456,\n",
       "  0.9977213740348816,\n",
       "  0.9981553554534912,\n",
       "  0.9977213740348816,\n",
       "  0.9977213740348816,\n",
       "  0.9979383945465088]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc01b7d-a7ab-4284-964d-68598a93d134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(history.history[\\'loss\\'], label=\\' training data\\')\\nplt.plot(history.history[\\'val_loss\\'], label=\\'validation data\\')\\nplt.title(\\'Loss for Text Classification\\')\\nplt.ylabel(\\'Loss value\\')\\nplt.xlabel(\\'No. epoch\\')\\nplt.legend(loc=\"upper left\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(history.history['loss'], label=' training data')\n",
    "plt.plot(history.history['val_loss'], label='validation data')\n",
    "plt.title('Loss for Text Classification')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6006641d-83c9-425e-b84d-9451bbd391d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(history.history[\\'categorical_accuracy\\'], label=\\' (training data)\\')\\nplt.plot(history.history[\\'val_categorical_accuracy\\'], label=\\'CategoricalCrossentropy (validation data)\\')\\nplt.title(\\'CategoricalAccuracy for Text Classification\\')\\nplt.ylabel(\\'CategoricalAccuracy value\\')\\nplt.xlabel(\\'No. epoch\\')\\nplt.legend(loc=\"upper left\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.plot(history.history['categorical_accuracy'], label=' (training data)')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='CategoricalCrossentropy (validation data)')\n",
    "plt.title('CategoricalAccuracy for Text Classification')\n",
    "plt.ylabel('CategoricalAccuracy value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae86a21e-5baa-43a8-b37a-0525e23af208",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer._name = layer.name+\"_word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71d38779-c46b-4600-aaa7-752e4d5f6120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\URLword\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\URLword\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword') \n",
    "json_string4 = URLword.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c07f08ee-072a-494b-9587-97c719629c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword\\\\URLword.json', 'w') as outfile4:\n",
    "    json.dump(json_string4, outfile4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "093fad61-1d01-4441-af0d-3e758dcfd3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 40, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reload model\n",
    "\n",
    "new_model = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4aa4ad50-70d5-491a-86a6-c0ec45ac1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword\\\\URLword.json') as json_file:\n",
    "    json_string = json.load(json_file)\n",
    "tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0593ab06-c7f7-45ad-99d3-0bb97114bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_9208\\532273747.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test  = np.array( tokenizer1.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test  = np.array( tokenizer1.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "285b5d0c-c6cc-4ad3-851c-d0dda819352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "[[0.9864073  0.01359272]\n",
      " [0.9703854  0.02961461]\n",
      " [0.92938405 0.07061591]\n",
      " ...\n",
      " [0.9523344  0.0476656 ]\n",
      " [0.9263759  0.07362404]\n",
      " [0.9869116  0.01308842]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on test  data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1d03231-1179-4974-8e41-a79d81b9e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake']= predict_results\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '0'),0,test_data.pred_fake)\n",
    "test_data['pred_fake'] = np.where((test_data.pred_fake == '1'),1,test_data.pred_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31a747c5-d56b-41b2-b46f-ddef6c577fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e92601-5e63-4df0-b3b3-6b2fdcb5902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pred_fake, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake']))\n",
    "test_data['pred_fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f32efb08-5b28-4e69-8718-4bd1d01411ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1429\n",
      "           1       0.88      0.66      0.76       184\n",
      "\n",
      "    accuracy                           0.95      1613\n",
      "   macro avg       0.92      0.83      0.86      1613\n",
      "weighted avg       0.95      0.95      0.95      1613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ed79082-76d1-4346-932c-e970cd4fee8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9208\\3547871458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprecisionscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maccuracyscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrecallscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf1score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "precisionscore = precision_score(y_test, new_model.predict(x_test))\n",
    "accuracyscore = accuracy_score(y_test, new_model.predict(x_test))\n",
    "recallscore = recall_score(y_test, new_model.predict(x_test))\n",
    "f1score = f1_score(y_test, new_model.predict(x_test))\n",
    "cm = confusion_matrix(y_test, new_model.predict(x_test))\n",
    "\n",
    "print(precisionscore, accuracyscore, recallscore, f1score, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b9202e-a347-4243-a327-1e3432c9e19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac01755-1aa1-41d5-8069-c8a0b390ea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317cd01-9359-4647-9155-5fc15fc86d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
