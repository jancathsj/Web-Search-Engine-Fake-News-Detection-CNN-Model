{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe88f91-6205-4375-ae9b-a86d5d0e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%%script C:\\Users\\Jan Catherine\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c542dc-142b-4bd7-a809-85189871a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5778bf7-46f3-494b-a66f-1b9c354f4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../Data_Collection_03/02_Preprocessing/05_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aed2f12-08dd-4251-97c2-18310735932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4409ce-fa2b-4138-8f5e-96db2d536f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('02_All_Test.csv', encoding='latin-1')\n",
    "\n",
    "test_data = testdata\n",
    "\n",
    "test_data.dropna(axis = 0, how ='any',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e971202-1a9c-4734-a27b-b7f93e543ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4_1 (Embedding)   (None, 90, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_4_1 (Conv1D)         (None, 88, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4_1 (  (None, 128)               0         \n",
      " GlobalMaxPooling1D)                                             \n",
      "                                                                 \n",
      " dropout_4_1 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4_1 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model1 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Title')\n",
    "new_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7640a9e3-83af-4415-9736-121cefc0e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Title\\\\Title.json') as json_file1:\n",
    "    json_string1 = json.loads(json_file1.read())\n",
    "tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(json_string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c166ed39-243a-4609-af70-86705b27ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model2 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc')\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4899e742-3ae6-4c20-901b-f463e09f18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc\\\\Desc.json') as json_file2:\n",
    "    json_string2 = json.loads(json_file2.read())\n",
    "tokenizer2 = tf.keras.preprocessing.text.tokenizer_from_json(json_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be9b631-98a7-4812-b28b-7e3c7dbc51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model3 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar')\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3a4644-a214-4c52-a1cf-457ac070c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar\\\\URLchar.json') as json_file3:\n",
    "    json_string3 = json.load(json_file3)\n",
    "tokenizer3 = tf.keras.preprocessing.text.tokenizer_from_json(json_string3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33f56cb-4f35-4b26-a290-00d503ac3470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4_word (Embeddin  (None, 40, 64)            750016    \n",
      " g)                                                              \n",
      "                                                                 \n",
      " conv1d_4_word (Conv1D)      (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4_wor  (None, 128)               0         \n",
      " d (GlobalMaxPooling1D)                                          \n",
      "                                                                 \n",
      " dropout_4_word (Dropout)    (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4_word (Dense)        (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model4 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword')\n",
    "new_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f244ed75-35d3-4a3e-8a57-9b2e779d8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword\\\\URLword.json') as json_file4:\n",
    "    json_string4 = json.load(json_file4)\n",
    "tokenizer4 = tf.keras.preprocessing.text.tokenizer_from_json(json_string4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b732e5c-0c42-4578-8048-d607c978df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " average (Average)           (None, 2)                    0         ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]',             \n",
      "                                                                     'input_3[0][0]',             \n",
      "                                                                     'input_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model5 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_URL')\n",
    "new_model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af41b1a9-aa08-4c05-97b9-a33e5bacdd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " average (Average)           (None, 2)                    0         ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model6 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_No_URL')\n",
    "new_model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b05085-8bb9-49fd-9948-3543d17c3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13728\\3328888694.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test1  = np.array( tokenizer1.texts_to_sequences(test_data['Title'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test1  = np.array( tokenizer1.texts_to_sequences(test_data['Title'].tolist()) )\n",
    "x_test1 = pad_sequences(x_test1, padding='post', maxlen=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a357ba14-fe95-42e6-b8db-4c1ca52b2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13728\\4054164706.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test2  = np.array( tokenizer2.texts_to_sequences(test_data['Description'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test2  = np.array( tokenizer2.texts_to_sequences(test_data['Description'].tolist()) )\n",
    "x_test2 = pad_sequences(x_test2, padding='post', maxlen=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1277d5e-eaff-43fa-925e-a8630a0d7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13728\\1739419470.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test3  = np.array( tokenizer3.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test3  = np.array( tokenizer3.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "x_test3 = pad_sequences(x_test3, padding='post', maxlen=260)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0df62860-d139-4a8d-b9c1-bac139fa9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13728\\2258211110.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test4  = np.array( tokenizer4.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test4  = np.array( tokenizer4.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "x_test4 = pad_sequences(x_test4, padding='post', maxlen=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fdaacfc-e0a9-4bf5-a021-2ed3c1b28137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "27/27 [==============================] - 0s 4ms/step\n",
      "[[9.9958450e-01 4.1550127e-04]\n",
      " [9.9982953e-01 1.7049181e-04]\n",
      " [9.8916990e-01 1.0830079e-02]\n",
      " ...\n",
      " [9.7679418e-01 2.3205804e-02]\n",
      " [9.8604935e-01 1.3950633e-02]\n",
      " [9.9202150e-01 7.9784933e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions1 = new_model1.predict(x_test1)\n",
    "print(predictions1)\n",
    "predict_results1 = predictions1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39f8cfcc-eabc-4e55-8905-edd3edf69190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "27/27 [==============================] - 0s 3ms/step\n",
      "[[0.94111526 0.05888475]\n",
      " [0.99540746 0.00459254]\n",
      " [0.97648996 0.02351002]\n",
      " ...\n",
      " [0.97934484 0.02065513]\n",
      " [0.9979575  0.00204247]\n",
      " [0.9808166  0.01918339]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions2 = new_model2.predict(x_test2)\n",
    "print(predictions2)\n",
    "predict_results2 = predictions2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4450309-870c-4e73-ad8c-be61adc50fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "27/27 [==============================] - 0s 6ms/step\n",
      "[[0.79100466 0.20899567]\n",
      " [0.87620866 0.12379212]\n",
      " [0.8144461  0.18555513]\n",
      " ...\n",
      " [0.4058216  0.59417593]\n",
      " [0.50849885 0.4914994 ]\n",
      " [0.98134935 0.01865079]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions3 = new_model3.predict(x_test3)\n",
    "print(predictions3)\n",
    "predict_results3 = predictions3.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d78de671-ce38-415f-a2e8-de04dfe18e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "[[0.9915817  0.00841829]\n",
      " [0.99103314 0.0089669 ]\n",
      " [0.9577367  0.04226334]\n",
      " ...\n",
      " [0.96305877 0.03694125]\n",
      " [0.9608643  0.0391357 ]\n",
      " [0.9938769  0.00612312]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions4 = new_model4.predict(x_test4)\n",
    "print(predictions4)\n",
    "predict_results4 = predictions4.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0591c7a7-0f9a-45ec-bb0c-eff0ff458290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "[[0.93082154 0.06917855]\n",
      " [0.9656197  0.03438051]\n",
      " [0.9344607  0.06553964]\n",
      " ...\n",
      " [0.83125484 0.16874452]\n",
      " [0.8633425  0.13665704]\n",
      " [0.9870161  0.01298395]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions5 = new_model5.predict([predictions1, predictions2, predictions3, predictions4 ])\n",
    "print(predictions5)\n",
    "predict_results5 = predictions5.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db243396-9d14-4035-85e2-abeec4ac7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "[[0.9703499  0.02965013]\n",
      " [0.9976185  0.00238151]\n",
      " [0.9828299  0.01717005]\n",
      " ...\n",
      " [0.97806954 0.02193047]\n",
      " [0.99200344 0.00799655]\n",
      " [0.9864191  0.01358094]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions6 = new_model6.predict([predictions1, predictions2])\n",
    "print(predictions6)\n",
    "predict_results6 = predictions6.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b025605-99cd-4ee1-ad46-77962722e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_title']= predict_results1\n",
    "test_data['pred_fake_title'] = np.where((test_data.pred_fake_title == '0'),0,test_data.pred_fake_title)\n",
    "test_data['pred_fake_title'] = np.where((test_data.pred_fake_title == '1'),1,test_data.pred_fake_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a21b0166-ac64-40d7-8cea-a5d1f3cc6c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       699\n",
      "           1       0.68      0.19      0.29       151\n",
      "\n",
      "    accuracy                           0.84       850\n",
      "   macro avg       0.77      0.58      0.60       850\n",
      "weighted avg       0.82      0.84      0.80       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_title'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0d0b30-d0c6-44b3-b2c0-e9dccdaea2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_desc']= predict_results2\n",
    "test_data['pred_fake_desc'] = np.where((test_data.pred_fake_desc == '0'),0,test_data.pred_fake_desc)\n",
    "test_data['pred_fake_desc'] = np.where((test_data.pred_fake_desc == '1'),1,test_data.pred_fake_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d81fb482-bb10-47a2-8978-6056461c5823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       699\n",
      "           1       0.47      0.19      0.27       151\n",
      "\n",
      "    accuracy                           0.82       850\n",
      "   macro avg       0.66      0.57      0.58       850\n",
      "weighted avg       0.78      0.82      0.78       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_desc'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42714719-daa7-4985-afa8-2cfd8b99249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_char']= predict_results3\n",
    "test_data['pred_fake_char'] = np.where((test_data.pred_fake_char == '0'),0,test_data.pred_fake_char)\n",
    "test_data['pred_fake_char'] = np.where((test_data.pred_fake_char == '1'),1,test_data.pred_fake_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0992204e-90ba-49c5-816c-e9780633b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       699\n",
      "           1       0.40      0.31      0.35       151\n",
      "\n",
      "    accuracy                           0.80       850\n",
      "   macro avg       0.63      0.61      0.61       850\n",
      "weighted avg       0.78      0.80      0.78       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_char'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f8c3048-9e6b-4376-a071-5796a4bba7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_word']= predict_results4\n",
    "test_data['pred_fake_word'] = np.where((test_data.pred_fake_word == '0'),0,test_data.pred_fake_word)\n",
    "test_data['pred_fake_word'] = np.where((test_data.pred_fake_word == '1'),1,test_data.pred_fake_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa9a2a81-f926-45cf-9a1e-9e94bdf0bd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91       699\n",
      "           1       0.73      0.24      0.36       151\n",
      "\n",
      "    accuracy                           0.85       850\n",
      "   macro avg       0.80      0.61      0.64       850\n",
      "weighted avg       0.83      0.85      0.82       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_word'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "741788ba-355f-4edc-8042-4718b62c2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_text']= predict_results6\n",
    "test_data['pred_fake_text'] = np.where((test_data.pred_fake_text == '0'),0,test_data.pred_fake_text)\n",
    "test_data['pred_fake_text'] = np.where((test_data.pred_fake_text == '1'),1,test_data.pred_fake_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81ffc59b-957f-43b2-a07c-9a4a4b7ded8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       699\n",
      "           1       0.82      0.09      0.17       151\n",
      "\n",
      "    accuracy                           0.84       850\n",
      "   macro avg       0.83      0.54      0.54       850\n",
      "weighted avg       0.83      0.84      0.78       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_text'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2777b7c2-726b-4534-9c88-2bf4c2b6829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_URL']= predict_results5\n",
    "test_data['pred_fake_URL'] = np.where((test_data.pred_fake_URL == '0'),0,test_data.pred_fake_URL)\n",
    "test_data['pred_fake_URL'] = np.where((test_data.pred_fake_URL == '1'),1,test_data.pred_fake_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40891c52-fe23-48d2-b78c-3326d224b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d754639-5fd5-4baa-a698-23042e1c69be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pred_fake_URL, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake_URL']))\n",
    "test_data['pred_fake_URL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d22cfb2e-140e-424c-9622-111a8e06227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       699\n",
      "           1       0.95      0.13      0.22       151\n",
      "\n",
      "    accuracy                           0.84       850\n",
      "   macro avg       0.90      0.56      0.57       850\n",
      "weighted avg       0.86      0.84      0.79       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_URL'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "290f462a-11a6-4918-8811-cb81478bbe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('All_URL_title_02.txt', predictions1)\n",
    "np.savetxt('All_URL_desc_02.txt', predictions2)\n",
    "np.savetxt('All_URL_char_02.txt', predictions3)\n",
    "np.savetxt('All_URL_word_02.txt', predictions4)\n",
    "np.savetxt('All_text_02.txt', predictions5)\n",
    "np.savetxt('All_URL_02.txt', predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967fd991-7b3c-43ab-8d74-87119b69b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('NewTest_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffb025-cb5f-4fc9-b05e-768736cc9fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
