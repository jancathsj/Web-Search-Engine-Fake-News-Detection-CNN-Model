{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe88f91-6205-4375-ae9b-a86d5d0e955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%%script C:\\Users\\Jan Catherine\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c542dc-142b-4bd7-a809-85189871a13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5778bf7-46f3-494b-a66f-1b9c354f4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../Data_Collection_02/02_Preprocessing/05_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aed2f12-08dd-4251-97c2-18310735932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4409ce-fa2b-4138-8f5e-96db2d536f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('02_All_Train.csv', encoding='latin-1')\n",
    "testdata = pd.read_csv('02_All_Test.csv', encoding='latin-1')\n",
    "\n",
    "train_data = dataset\n",
    "test_data = testdata\n",
    "\n",
    "test_data.dropna(axis = 0, how ='any',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e971202-1a9c-4734-a27b-b7f93e543ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4_1 (Embedding)   (None, 90, 64)            750016    \n",
      "                                                                 \n",
      " conv1d_4_1 (Conv1D)         (None, 88, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4_1 (  (None, 128)               0         \n",
      " GlobalMaxPooling1D)                                             \n",
      "                                                                 \n",
      " dropout_4_1 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4_1 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model1 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Title')\n",
    "new_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7640a9e3-83af-4415-9736-121cefc0e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Title\\\\Title.json') as json_file1:\n",
    "    json_string1 = json.loads(json_file1.read())\n",
    "tokenizer1 = tf.keras.preprocessing.text.tokenizer_from_json(json_string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c166ed39-243a-4609-af70-86705b27ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1305026 (4.98 MB)\n",
      "Trainable params: 1305026 (4.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model2 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc')\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4899e742-3ae6-4c20-901b-f463e09f18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\Desc\\\\Desc.json') as json_file2:\n",
    "    json_string2 = json.loads(json_file2.read())\n",
    "tokenizer2 = tf.keras.preprocessing.text.tokenizer_from_json(json_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be9b631-98a7-4812-b28b-7e3c7dbc51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 260, 64)           750016    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 258, 128)          24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model3 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar')\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3a4644-a214-4c52-a1cf-457ac070c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLchar\\\\URLchar.json') as json_file3:\n",
    "    json_string3 = json.load(json_file3)\n",
    "tokenizer3 = tf.keras.preprocessing.text.tokenizer_from_json(json_string3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33f56cb-4f35-4b26-a290-00d503ac3470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4_word (Embeddin  (None, 40, 64)            750016    \n",
      " g)                                                              \n",
      "                                                                 \n",
      " conv1d_4_word (Conv1D)      (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d_4_wor  (None, 128)               0         \n",
      " d (GlobalMaxPooling1D)                                          \n",
      "                                                                 \n",
      " dropout_4_word (Dropout)    (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4_word (Dense)        (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 774978 (2.96 MB)\n",
      "Trainable params: 774978 (2.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model4 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword')\n",
    "new_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f244ed75-35d3-4a3e-8a57-9b2e779d8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\URLword\\\\URLword.json') as json_file4:\n",
    "    json_string4 = json.load(json_file4)\n",
    "tokenizer4 = tf.keras.preprocessing.text.tokenizer_from_json(json_string4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43e2d9cc-e844-481e-9a64-3d8399d18eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " average (Average)           (None, 2)                    0         ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model5 = tf.keras.models.load_model('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_No_URL')\n",
    "new_model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b05085-8bb9-49fd-9948-3543d17c3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13820\\3328888694.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test1  = np.array( tokenizer1.texts_to_sequences(test_data['Title'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test1  = np.array( tokenizer1.texts_to_sequences(test_data['Title'].tolist()) )\n",
    "x_test1 = pad_sequences(x_test1, padding='post', maxlen=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a357ba14-fe95-42e6-b8db-4c1ca52b2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13820\\4054164706.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test2  = np.array( tokenizer2.texts_to_sequences(test_data['Description'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test2  = np.array( tokenizer2.texts_to_sequences(test_data['Description'].tolist()) )\n",
    "x_test2 = pad_sequences(x_test2, padding='post', maxlen=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1277d5e-eaff-43fa-925e-a8630a0d7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13820\\1739419470.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test3  = np.array( tokenizer3.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test3  = np.array( tokenizer3.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "x_test3 = pad_sequences(x_test3, padding='post', maxlen=260)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df62860-d139-4a8d-b9c1-bac139fa9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Catherine\\AppData\\Local\\Temp\\ipykernel_13820\\2258211110.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test4  = np.array( tokenizer4.texts_to_sequences(test_data['URL'].tolist()) )\n"
     ]
    }
   ],
   "source": [
    "x_test4  = np.array( tokenizer4.texts_to_sequences(test_data['URL'].tolist()) )\n",
    "x_test4 = pad_sequences(x_test4, padding='post', maxlen=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d21c46b2-6792-4b29-b787-607fffdd8db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmerged_layers = concatenate([new_model1.output, new_model2.output, new_model3.output, new_model4.output])\\nx = BatchNormalization()(merged_layers)\\nx = Dense(300)(x)\\nx = PReLU()(x)\\nx = Dropout(0.2)(x)\\nx = Dense(1)(x)\\nx = BatchNormalization()(x)\\nout = Activation('sigmoid')(x)\\n\\nmerged_model = Model([new_model1.input(), new_model2.input(), new_model3.input(), new_model4.input()], [out])\\nmerged_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['CategoricalAccuracy'])\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras. models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "\"\"\"\n",
    "merged_layers = concatenate([new_model1.output, new_model2.output, new_model3.output, new_model4.output])\n",
    "x = BatchNormalization()(merged_layers)\n",
    "x = Dense(300)(x)\n",
    "x = PReLU()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "x = BatchNormalization()(x)\n",
    "out = Activation('sigmoid')(x)\n",
    "\n",
    "merged_model = Model([new_model1.input(), new_model2.input(), new_model3.input(), new_model4.input()], [out])\n",
    "merged_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['CategoricalAccuracy'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f28d8dc-4764-4428-87bb-0b67e294a821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 90, 64]\n",
      "[None, 88, 128]\n",
      "[None, 128]\n",
      "[None, 128]\n",
      "[None, 2]\n"
     ]
    }
   ],
   "source": [
    "for layer in new_model1.layers:\n",
    "    print(layer.get_output_at(0).get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f804b26-07d0-4674-be98-c81a2d18a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model=tf.keras.layers.Average()([new_model1.output, new_model2.output, new_model3.output, new_model4.output])\n",
    "#merged_model=BatchNormalization()(merged_model)\n",
    "#merged_model=tf.keras.layers.Dense(128, activation='relu')(merged_model)\n",
    "#merged_model=tf.keras.layers.Dropout(0.2)(merged_model)\n",
    "#merged_model=tf.keras.layers.Dense(2,activation='relu')(merged_model)\n",
    "#merged_model = BatchNormalization()(merged_model)\n",
    "\n",
    "final_model = tf.keras.models.Model(inputs=[new_model1.output, new_model2.output, new_model3.output, new_model4.output], outputs=merged_model)\n",
    "final_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['CategoricalAccuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03e61ee3-7f10-40d5-b814-be7d7c717311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " average (Average)           (None, 2)                    0         ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]',             \n",
      "                                                                     'input_3[0][0]',             \n",
      "                                                                     'input_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fdaacfc-e0a9-4bf5-a021-2ed3c1b28137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 4ms/step\n",
      "[[0.9986129  0.00138709]\n",
      " [0.99433863 0.00566135]\n",
      " [0.99058545 0.00941452]\n",
      " ...\n",
      " [0.00372173 0.9962783 ]\n",
      " [0.9556978  0.04430221]\n",
      " [0.9832606  0.01673941]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions1 = new_model1.predict(x_test1)\n",
    "print(predictions1)\n",
    "predict_results1 = predictions1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39f8cfcc-eabc-4e55-8905-edd3edf69190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "[[0.98725384 0.01274614]\n",
      " [0.99856377 0.00143621]\n",
      " [0.9836872  0.01631275]\n",
      " ...\n",
      " [0.00634583 0.9936542 ]\n",
      " [0.9606546  0.03934541]\n",
      " [0.9776184  0.02238159]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions2 = new_model2.predict(x_test2)\n",
    "print(predictions2)\n",
    "predict_results2 = predictions2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4450309-870c-4e73-ad8c-be61adc50fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 7ms/step\n",
      "[[0.99622256 0.00377741]\n",
      " [0.9815708  0.01842912]\n",
      " [0.7696982  0.23030218]\n",
      " ...\n",
      " [0.8019059  0.19809413]\n",
      " [0.9904026  0.00959739]\n",
      " [0.9476664  0.05233336]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions3 = new_model3.predict(x_test3)\n",
    "print(predictions3)\n",
    "predict_results3 = predictions3.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d78de671-ce38-415f-a2e8-de04dfe18e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "[[0.9864073  0.01359272]\n",
      " [0.9703854  0.02961461]\n",
      " [0.92938405 0.07061591]\n",
      " ...\n",
      " [0.9523344  0.0476656 ]\n",
      " [0.9263759  0.07362404]\n",
      " [0.9869116  0.01308842]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions4 = new_model4.predict(x_test4)\n",
    "print(predictions4)\n",
    "predict_results4 = predictions4.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eec953c6-ff76-4397-8a40-d199f32a28ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "[[0.9929334  0.00706661]\n",
      " [0.9964512  0.00354878]\n",
      " [0.98713636 0.01286364]\n",
      " ...\n",
      " [0.00503378 0.99496627]\n",
      " [0.9581762  0.04182381]\n",
      " [0.9804395  0.0195605 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions5 = new_model5.predict([predictions1, predictions2])\n",
    "print(predictions5)\n",
    "predict_results5 = predictions5.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db243396-9d14-4035-85e2-abeec4ac7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for all samples\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "[[0.99212414 0.00787584]\n",
      " [0.98621464 0.01378532]\n",
      " [0.9183387  0.08166134]\n",
      " ...\n",
      " [0.44107696 0.55892307]\n",
      " [0.9582827  0.04171726]\n",
      " [0.97386426 0.0261357 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for all samples\")\n",
    "predictions = final_model.predict([predictions1, predictions2, predictions3, predictions4 ])\n",
    "print(predictions)\n",
    "predict_results = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6afcdb43-300d-4f03-8668-faee4e47a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_title']= predict_results1\n",
    "test_data['pred_fake_title'] = np.where((test_data.pred_fake_title == '0'),0,test_data.pred_fake_title)\n",
    "test_data['pred_fake_title'] = np.where((test_data.pred_fake_title == '1'),1,test_data.pred_fake_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2105fbb-0516-452c-80be-fb21d864d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1428\n",
      "           1       0.76      0.71      0.73       184\n",
      "\n",
      "    accuracy                           0.94      1612\n",
      "   macro avg       0.86      0.84      0.85      1612\n",
      "weighted avg       0.94      0.94      0.94      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_title'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e7eb9e-f105-44f7-9b84-1458dfe90384",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_desc']= predict_results2\n",
    "test_data['pred_fake_desc'] = np.where((test_data.pred_fake_desc == '0'),0,test_data.pred_fake_desc)\n",
    "test_data['pred_fake_desc'] = np.where((test_data.pred_fake_desc == '1'),1,test_data.pred_fake_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb05bd5f-4dde-4464-9e63-2515bc837110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1428\n",
      "           1       0.60      0.65      0.62       184\n",
      "\n",
      "    accuracy                           0.91      1612\n",
      "   macro avg       0.78      0.80      0.79      1612\n",
      "weighted avg       0.91      0.91      0.91      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_desc'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c743881d-23e2-4b10-8656-e9cee860ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_char']= predict_results3\n",
    "test_data['pred_fake_char'] = np.where((test_data.pred_fake_char == '0'),0,test_data.pred_fake_char)\n",
    "test_data['pred_fake_char'] = np.where((test_data.pred_fake_char == '1'),1,test_data.pred_fake_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffea76dc-082c-43c0-b3de-9687d91213a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1428\n",
      "           1       0.73      0.73      0.73       184\n",
      "\n",
      "    accuracy                           0.94      1612\n",
      "   macro avg       0.85      0.85      0.85      1612\n",
      "weighted avg       0.94      0.94      0.94      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_char'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ea500fc-03ea-4493-8bb1-b7637ffb7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_word']= predict_results4\n",
    "test_data['pred_fake_word'] = np.where((test_data.pred_fake_word == '0'),0,test_data.pred_fake_word)\n",
    "test_data['pred_fake_word'] = np.where((test_data.pred_fake_word == '1'),1,test_data.pred_fake_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4310cba0-a0c3-4395-9de8-1a7d82f667d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1428\n",
      "           1       0.88      0.66      0.76       184\n",
      "\n",
      "    accuracy                           0.95      1612\n",
      "   macro avg       0.92      0.83      0.86      1612\n",
      "weighted avg       0.95      0.95      0.95      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_word'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf0eb9da-7136-4b36-a615-ed24bcf5e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_text']= predict_results5\n",
    "test_data['pred_fake_text'] = np.where((test_data.pred_fake_text == '0'),0,test_data.pred_fake_text)\n",
    "test_data['pred_fake_text'] = np.where((test_data.pred_fake_text == '1'),1,test_data.pred_fake_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8011498-1730-4755-8e93-5e7353786d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f229ba04-6cc4-4d35-a917-8eeba57612f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pred_fake_text, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake_text']))\n",
    "test_data['pred_fake_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9758dd6b-fa22-467f-90de-f01540eebd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1428\n",
      "           1       0.87      0.71      0.78       184\n",
      "\n",
      "    accuracy                           0.95      1612\n",
      "   macro avg       0.92      0.85      0.88      1612\n",
      "weighted avg       0.95      0.95      0.95      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_text'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2777b7c2-726b-4534-9c88-2bf4c2b6829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred_fake_URL']= predict_results\n",
    "test_data['pred_fake_URL'] = np.where((test_data.pred_fake_URL == '0'),0,test_data.pred_fake_URL)\n",
    "test_data['pred_fake_URL'] = np.where((test_data.pred_fake_URL == '1'),1,test_data.pred_fake_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40891c52-fe23-48d2-b78c-3326d224b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['Fake']))\n",
    "test_data['Fake'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d754639-5fd5-4baa-a698-23042e1c69be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pred_fake_URL, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test_data['pred_fake_URL']))\n",
    "test_data['pred_fake_URL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d22cfb2e-140e-424c-9622-111a8e06227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1428\n",
      "           1       0.95      0.68      0.79       184\n",
      "\n",
      "    accuracy                           0.96      1612\n",
      "   macro avg       0.95      0.84      0.89      1612\n",
      "weighted avg       0.96      0.96      0.96      1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 1]\n",
    "    \n",
    "print(classification_report(test_data['Fake'].tolist(),test_data['pred_fake_URL'].tolist(),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f32cb88f-8939-47e5-9ff5-a5250318b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('All_URL_title.txt', predictions1)\n",
    "np.savetxt('All_URL_desc.txt', predictions2)\n",
    "np.savetxt('All_URL_char.txt', predictions3)\n",
    "np.savetxt('All_URL_word.txt', predictions4)\n",
    "np.savetxt('All_text.txt', predictions5)\n",
    "np.savetxt('All_URL.txt', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dad2004-d7cb-4e4e-be41-acdd4948428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\All_URL\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jan Catherine\\Documents\\CMSC Notes\\CMSC 190 Part 2\\Codes\\CNN\\All_URL\\assets\n"
     ]
    }
   ],
   "source": [
    "final_model.save('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_URL') \n",
    "#json_string1 = tokenizer.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d62370d9-d8c0-4b70-9615-f56e5ee9eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('Test_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fd991-7b3c-43ab-8d74-87119b69b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#with open('C:\\\\Users\\\\Jan Catherine\\\\Documents\\\\CMSC Notes\\\\CMSC 190 Part 2\\\\Codes\\\\CNN\\\\All_URL\\\\All_URL.json', 'w') as outfile:\n",
    "#    json.dump(json_string, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
